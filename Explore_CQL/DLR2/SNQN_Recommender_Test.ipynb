{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Ijoc7SsgNR-G","74DxOJZWN9u2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# Self-Attentive Sequential Recommender (SASRec) + Supervised Negative Q-Learning (SNQN) Recommender with CQL Loss\n","\n","In this notebook, we train an SASRec-SNQN model to recommend a list of items to users in the dataset. We are using RetailRocket and H&M datasets to train this model. We will compare the success of models with the use of CQL Loss and without it. "],"metadata":{"id":"Kfw3EGVCMdNb"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"Pb78pX53MdS-"}},{"cell_type":"code","source":["# Clone our repository\n","!git clone https://github.com/szheng3/recommendation-system.git\n","# Install Requirements\n","!pip install trfl"],"metadata":{"id":"hYJWxKjKMpwm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RetailRocket"],"metadata":{"id":"hltu5efIMdYz"}},{"cell_type":"markdown","source":["### Prepare the Data"],"metadata":{"id":"JusFF_yiNPM0"}},{"cell_type":"code","source":["# Download the data\n","!wget https://aipi590.s3.amazonaws.com/events.csv -P 'recommendation-system/Explore_CQL/Data/RR_data'\n"],"metadata":{"id":"aK1eQEkzNIWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the data\n","!python 'recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer.py' --data='recommendation-system/Explore_CQL/Data/RR_data'"],"metadata":{"id":"dW9e_3a_PC0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tf_upgrade_v2 \\\n","  --infile 'recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py' \\\n","  --outfile 'recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py' \\\n","  --reportfile report_SNQN.txt"],"metadata":{"id":"arS7d2RCxmnA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"SvNXO7FNN8FQ"}},{"cell_type":"markdown","source":["#### Without CQL Loss"],"metadata":{"id":"sRerunKJOBWc"}},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --data=\"recommendation-system/Explore_CQL/Data/RR_data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"927Gbel7OJfv","outputId":"2845f2a8-b89e-4278-8c52-12505ec0852b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-02 16:22:00.707715: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-02 16:22:01.865193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Not using CQL loss\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:191: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  self.seq = tf.compat.v1.layers.dropout(self.seq,\n","2023-05-02 16:22:04.258908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","2023-05-02 16:22:04.338297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:04.950005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:04.950307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 16:22:05.141453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 16:22:05.201217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 16:22:05.241945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:222: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","Not using CQL loss\n","2023-05-02 16:22:06.865675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 16:22:07.026306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 16:22:07.086102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 16:22:07.150771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 16:22:13.130069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:13.130478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:13.130674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:15.868919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:15.869264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:15.869516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-02 16:22:15.869677: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-02 16:22:15.869724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14518 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-05-02 16:22:15.924440: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n","2023-05-02 16:22:21.166026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.000000\n","clicks hr ndcg @ 5 : 0.000043, 0.000024\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 2.200000\n","clicks hr ndcg @ 10 : 0.000094, 0.000039\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.600000\n","clicks hr ndcg @ 15 : 0.000197, 0.000066\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 5.800000\n","clicks hr ndcg @ 20 : 0.000248, 0.000078\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.977384\n","the loss in 400th batch is: 10.629513\n","the loss in 600th batch is: 10.615710\n","the loss in 800th batch is: 10.633423\n","the loss in 1000th batch is: 10.455797\n","the loss in 1200th batch is: 10.448367\n","the loss in 1400th batch is: 10.125961\n","the loss in 1600th batch is: 9.966904\n","the loss in 1800th batch is: 9.913441\n","the loss in 2000th batch is: 9.748089\n","the loss in 2200th batch is: 9.577539\n","the loss in 2400th batch is: 9.655670\n","the loss in 2600th batch is: 9.154575\n","the loss in 2800th batch is: 9.270020\n","the loss in 3000th batch is: 9.369831\n","the loss in 3200th batch is: 8.896312\n","the loss in 3400th batch is: 8.789823\n","the loss in 3600th batch is: 8.773354\n","the loss in 3800th batch is: 8.534361\n","the loss in 4000th batch is: 8.304669\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6358.200000\n","clicks hr ndcg @ 5 : 0.180968, 0.142470\n","purchase hr and ndcg @5 : 0.380602, 0.324875\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7329.600000\n","clicks hr ndcg @ 10 : 0.212904, 0.152809\n","purchase hr and ndcg @10 : 0.420760, 0.337911\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7864.400000\n","clicks hr ndcg @ 15 : 0.230714, 0.157525\n","purchase hr and ndcg @15 : 0.441915, 0.343503\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8231.600000\n","clicks hr ndcg @ 20 : 0.243242, 0.160487\n","purchase hr and ndcg @20 : 0.455181, 0.346655\n","#############################################################\n","the loss in 4200th batch is: 8.417908\n","the loss in 4400th batch is: 8.189995\n","the loss in 4600th batch is: 8.359977\n","the loss in 4800th batch is: 8.272328\n","the loss in 5000th batch is: 8.669089\n","the loss in 5200th batch is: 8.230127\n","the loss in 5400th batch is: 8.279088\n","the loss in 5600th batch is: 8.338401\n","the loss in 5800th batch is: 8.079358\n","the loss in 6000th batch is: 7.812754\n","the loss in 6200th batch is: 7.525008\n","the loss in 6400th batch is: 7.640773\n","the loss in 6600th batch is: 7.764827\n","the loss in 6800th batch is: 7.387249\n","the loss in 7000th batch is: 7.427430\n","the loss in 7200th batch is: 7.408030\n","the loss in 7400th batch is: 7.610102\n","the loss in 7600th batch is: 7.681233\n","the loss in 7800th batch is: 7.424015\n","the loss in 8000th batch is: 7.346124\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8511.600000\n","clicks hr ndcg @ 5 : 0.243071, 0.189879\n","purchase hr and ndcg @5 : 0.506095, 0.432679\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9807.200000\n","clicks hr ndcg @ 10 : 0.287408, 0.204242\n","purchase hr and ndcg @10 : 0.552349, 0.447675\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10501.800000\n","clicks hr ndcg @ 15 : 0.311490, 0.210616\n","purchase hr and ndcg @15 : 0.575834, 0.453925\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10982.200000\n","clicks hr ndcg @ 20 : 0.328898, 0.214733\n","purchase hr and ndcg @20 : 0.588921, 0.457025\n","#############################################################\n","the loss in 8200th batch is: 7.285985\n","the loss in 8400th batch is: 7.302380\n","the loss in 8600th batch is: 7.066653\n","the loss in 8800th batch is: 7.433122\n","the loss in 9000th batch is: 6.742480\n","the loss in 9200th batch is: 7.183781\n","the loss in 9400th batch is: 6.970923\n","the loss in 9600th batch is: 6.626503\n","the loss in 9800th batch is: 7.275419\n","the loss in 10000th batch is: 6.727571\n","the loss in 10200th batch is: 6.709565\n","the loss in 10400th batch is: 6.440320\n","the loss in 10600th batch is: 6.767475\n","the loss in 10800th batch is: 7.006004\n","the loss in 11000th batch is: 6.400739\n","the loss in 11200th batch is: 6.935290\n","the loss in 11400th batch is: 6.756503\n","the loss in 11600th batch is: 7.062601\n","the loss in 11800th batch is: 6.277164\n","the loss in 12000th batch is: 6.384105\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9357.600000\n","clicks hr ndcg @ 5 : 0.268923, 0.209019\n","purchase hr and ndcg @5 : 0.549301, 0.466744\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10835.600000\n","clicks hr ndcg @ 10 : 0.319002, 0.225232\n","purchase hr and ndcg @10 : 0.604159, 0.484651\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11600.400000\n","clicks hr ndcg @ 15 : 0.345827, 0.232343\n","purchase hr and ndcg @15 : 0.628720, 0.491164\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12115.200000\n","clicks hr ndcg @ 20 : 0.364150, 0.236673\n","purchase hr and ndcg @20 : 0.644138, 0.494808\n","#############################################################\n","the loss in 12200th batch is: 6.680195\n","the loss in 12400th batch is: 6.369853\n","the loss in 12600th batch is: 6.661934\n","the loss in 12800th batch is: 6.356616\n","the loss in 13000th batch is: 6.529801\n","the loss in 13200th batch is: 6.227901\n","the loss in 13400th batch is: 6.036675\n","the loss in 13600th batch is: 6.018447\n","the loss in 13800th batch is: 6.174026\n","the loss in 14000th batch is: 6.509125\n","the loss in 14200th batch is: 6.580362\n","the loss in 14400th batch is: 6.465673\n","the loss in 14600th batch is: 6.471811\n","the loss in 14800th batch is: 6.177808\n","the loss in 15000th batch is: 6.372905\n","the loss in 15200th batch is: 5.797319\n","the loss in 15400th batch is: 5.818886\n","the loss in 15600th batch is: 6.262771\n","the loss in 15800th batch is: 6.030782\n","the loss in 16000th batch is: 6.362549\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9679.200000\n","clicks hr ndcg @ 5 : 0.277238, 0.215551\n","purchase hr and ndcg @5 : 0.572069, 0.480950\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11203.800000\n","clicks hr ndcg @ 10 : 0.330633, 0.232879\n","purchase hr and ndcg @10 : 0.621370, 0.497019\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12060.600000\n","clicks hr ndcg @ 15 : 0.360236, 0.240723\n","purchase hr and ndcg @15 : 0.650771, 0.504814\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12601.400000\n","clicks hr ndcg @ 20 : 0.379370, 0.245244\n","purchase hr and ndcg @20 : 0.667444, 0.508770\n","#############################################################\n","the loss in 16200th batch is: 6.288742\n","the loss in 16400th batch is: 5.709789\n","the loss in 16600th batch is: 6.450407\n","the loss in 16800th batch is: 6.248559\n","the loss in 17000th batch is: 5.783088\n","the loss in 17200th batch is: 5.739073\n","the loss in 17400th batch is: 5.444746\n","the loss in 17600th batch is: 6.262999\n","the loss in 17800th batch is: 5.893496\n","the loss in 18000th batch is: 5.925061\n","the loss in 18200th batch is: 6.091447\n","the loss in 18400th batch is: 5.669939\n","the loss in 18600th batch is: 5.680949\n","the loss in 18800th batch is: 6.000193\n","the loss in 19000th batch is: 5.763915\n","the loss in 19200th batch is: 5.974432\n","the loss in 19400th batch is: 5.646607\n","the loss in 19600th batch is: 5.896039\n","the loss in 19800th batch is: 5.783902\n","the loss in 20000th batch is: 5.582708\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9826.400000\n","clicks hr ndcg @ 5 : 0.282630, 0.218180\n","purchase hr and ndcg @5 : 0.575834, 0.483414\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11463.600000\n","clicks hr ndcg @ 10 : 0.338529, 0.236298\n","purchase hr and ndcg @10 : 0.634815, 0.502512\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12286.400000\n","clicks hr ndcg @ 15 : 0.367491, 0.243971\n","purchase hr and ndcg @15 : 0.660810, 0.509378\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12842.600000\n","clicks hr ndcg @ 20 : 0.387027, 0.248586\n","purchase hr and ndcg @20 : 0.678559, 0.513568\n","#############################################################\n","the loss in 20200th batch is: 5.610570\n","the loss in 20400th batch is: 5.890161\n","the loss in 20600th batch is: 5.950427\n","the loss in 20800th batch is: 5.538362\n","the loss in 21000th batch is: 5.656792\n","the loss in 21200th batch is: 5.555799\n","the loss in 21400th batch is: 5.473662\n","the loss in 21600th batch is: 5.512620\n","the loss in 21800th batch is: 5.395177\n","the loss in 22000th batch is: 5.957176\n","the loss in 22200th batch is: 5.794560\n","the loss in 22400th batch is: 5.402810\n","the loss in 22600th batch is: 5.350037\n","the loss in 22800th batch is: 5.462202\n","the loss in 23000th batch is: 5.642299\n","the loss in 23200th batch is: 5.388049\n","the loss in 23400th batch is: 5.305897\n","the loss in 23600th batch is: 5.390495\n","the loss in 23800th batch is: 5.338051\n","the loss in 24000th batch is: 5.279614\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9815.800000\n","clicks hr ndcg @ 5 : 0.282263, 0.217491\n","purchase hr and ndcg @5 : 0.575475, 0.481769\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11483.000000\n","clicks hr ndcg @ 10 : 0.338845, 0.235870\n","purchase hr and ndcg @10 : 0.636967, 0.501751\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12351.400000\n","clicks hr ndcg @ 15 : 0.369542, 0.243993\n","purchase hr and ndcg @15 : 0.663858, 0.508906\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12918.400000\n","clicks hr ndcg @ 20 : 0.390266, 0.248894\n","purchase hr and ndcg @20 : 0.678559, 0.512387\n","#############################################################\n","the loss in 24200th batch is: 5.875093\n","the loss in 24400th batch is: 5.698742\n","the loss in 24600th batch is: 5.871020\n","the loss in 24800th batch is: 5.271716\n","the loss in 25000th batch is: 5.419109\n","the loss in 25200th batch is: 5.169915\n","the loss in 25400th batch is: 5.517007\n","the loss in 25600th batch is: 5.453178\n","the loss in 25800th batch is: 5.591232\n","the loss in 26000th batch is: 5.633075\n","the loss in 26200th batch is: 5.547218\n","the loss in 26400th batch is: 5.444351\n","the loss in 26600th batch is: 5.381378\n","the loss in 26800th batch is: 5.527333\n","the loss in 27000th batch is: 5.676052\n","the loss in 27200th batch is: 5.905437\n","the loss in 27400th batch is: 5.706457\n","the loss in 27600th batch is: 5.144376\n","the loss in 27800th batch is: 5.255087\n","the loss in 28000th batch is: 5.577253\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9823.600000\n","clicks hr ndcg @ 5 : 0.283152, 0.217449\n","purchase hr and ndcg @5 : 0.573144, 0.473423\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11477.400000\n","clicks hr ndcg @ 10 : 0.339546, 0.235723\n","purchase hr and ndcg @10 : 0.633023, 0.492949\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12350.400000\n","clicks hr ndcg @ 15 : 0.370824, 0.244008\n","purchase hr and ndcg @15 : 0.658300, 0.499665\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12921.800000\n","clicks hr ndcg @ 20 : 0.391181, 0.248820\n","purchase hr and ndcg @20 : 0.675332, 0.503674\n","#############################################################\n","the loss in 28200th batch is: 5.375381\n","the loss in 28400th batch is: 5.361580\n","the loss in 28600th batch is: 5.202417\n","the loss in 28800th batch is: 5.496878\n","the loss in 29000th batch is: 5.465096\n","the loss in 29200th batch is: 5.698426\n","the loss in 29400th batch is: 5.122571\n","the loss in 29600th batch is: 5.125851\n","the loss in 29800th batch is: 4.986910\n","the loss in 30000th batch is: 5.150343\n","the loss in 30200th batch is: 5.193822\n","the loss in 30400th batch is: 5.474663\n","the loss in 30600th batch is: 5.208161\n","the loss in 30800th batch is: 4.793618\n","the loss in 31000th batch is: 5.620852\n","the loss in 31200th batch is: 5.247018\n","the loss in 31400th batch is: 5.398716\n","the loss in 31600th batch is: 5.602034\n","the loss in 31800th batch is: 5.362632\n","the loss in 32000th batch is: 5.401455\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9803.600000\n","clicks hr ndcg @ 5 : 0.283579, 0.217402\n","purchase hr and ndcg @5 : 0.567766, 0.468361\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11498.600000\n","clicks hr ndcg @ 10 : 0.341649, 0.236223\n","purchase hr and ndcg @10 : 0.628003, 0.487991\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12368.600000\n","clicks hr ndcg @ 15 : 0.371645, 0.244160\n","purchase hr and ndcg @15 : 0.658121, 0.495965\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12946.400000\n","clicks hr ndcg @ 20 : 0.392274, 0.249037\n","purchase hr and ndcg @20 : 0.675152, 0.499989\n","#############################################################\n","the loss in 32200th batch is: 5.141258\n","the loss in 32400th batch is: 4.914002\n","the loss in 32600th batch is: 5.204987\n","the loss in 32800th batch is: 5.180467\n","the loss in 33000th batch is: 5.154908\n","the loss in 33200th batch is: 4.915678\n","the loss in 33400th batch is: 5.405549\n","the loss in 33600th batch is: 5.096559\n","the loss in 33800th batch is: 5.189063\n","the loss in 34000th batch is: 4.980518\n","the loss in 34200th batch is: 5.413762\n","the loss in 34400th batch is: 5.454261\n","the loss in 34600th batch is: 5.181112\n","the loss in 34800th batch is: 5.373058\n","the loss in 35000th batch is: 5.358018\n","the loss in 35200th batch is: 5.148527\n","the loss in 35400th batch is: 4.919680\n","the loss in 35600th batch is: 5.099511\n","the loss in 35800th batch is: 4.941413\n","the loss in 36000th batch is: 5.207917\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9828.200000\n","clicks hr ndcg @ 5 : 0.283861, 0.217836\n","purchase hr and ndcg @5 : 0.570993, 0.471691\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11507.400000\n","clicks hr ndcg @ 10 : 0.341512, 0.236566\n","purchase hr and ndcg @10 : 0.630154, 0.490854\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12376.400000\n","clicks hr ndcg @ 15 : 0.372192, 0.244699\n","purchase hr and ndcg @15 : 0.657225, 0.498068\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12960.800000\n","clicks hr ndcg @ 20 : 0.393146, 0.249654\n","purchase hr and ndcg @20 : 0.674077, 0.502051\n","#############################################################\n","the loss in 36200th batch is: 5.143485\n","the loss in 36400th batch is: 4.627952\n","the loss in 36600th batch is: 5.083685\n","the loss in 36800th batch is: 5.378787\n","the loss in 37000th batch is: 5.266705\n","the loss in 37200th batch is: 4.767355\n","the loss in 37400th batch is: 4.839482\n","the loss in 37600th batch is: 5.399065\n","the loss in 37800th batch is: 5.375087\n","the loss in 38000th batch is: 5.241321\n","the loss in 38200th batch is: 5.158791\n","the loss in 38400th batch is: 5.342113\n"]}]},{"cell_type":"markdown","source":["#### With CQL Loss"],"metadata":{"id":"fnXgyNMnOD37"}},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --CQL_alpha=0.5 --data=\"recommendation-system/Explore_CQL/Data/RR_data\""],"metadata":{"id":"igF4rV6JOKEt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d5e4b04-4075-49ce-eb6f-42f2c1b3814f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-03 14:44:24.600262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 14:44:25.823502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Using CQL loss.\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:191: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  self.seq = tf.compat.v1.layers.dropout(self.seq,\n","2023-05-03 14:44:28.318958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","2023-05-03 14:44:28.391534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:29.004804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:29.005158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 14:44:29.199482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 14:44:29.263177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 14:44:29.311706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:222: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","Using CQL loss.\n","2023-05-03 14:44:31.648160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 14:44:31.894436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 14:44:31.987505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 14:44:32.059673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 14:44:37.579375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:37.579762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:37.579968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:40.426911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:40.427230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:40.427460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 14:44:40.427618: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-03 14:44:40.427676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14518 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-05-03 14:44:40.487516: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n","2023-05-03 14:44:45.461632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 2.200000\n","clicks hr ndcg @ 5 : 0.000051, 0.000023\n","purchase hr and ndcg @5 : 0.000179, 0.000077\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3.600000\n","clicks hr ndcg @ 10 : 0.000111, 0.000042\n","purchase hr and ndcg @10 : 0.000179, 0.000077\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5.600000\n","clicks hr ndcg @ 15 : 0.000154, 0.000054\n","purchase hr and ndcg @15 : 0.000359, 0.000122\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10.200000\n","clicks hr ndcg @ 20 : 0.000222, 0.000070\n","purchase hr and ndcg @20 : 0.000896, 0.000248\n","#############################################################\n","the loss in 200th batch is: 22.282135\n","the loss in 400th batch is: 21.709068\n","the loss in 600th batch is: 21.732037\n","the loss in 800th batch is: 21.498011\n","the loss in 1000th batch is: 21.115566\n","the loss in 1200th batch is: 20.983307\n","the loss in 1400th batch is: 20.675680\n","the loss in 1600th batch is: 20.668114\n","the loss in 1800th batch is: 20.538061\n","the loss in 2000th batch is: 20.323044\n","the loss in 2200th batch is: 20.608892\n","the loss in 2400th batch is: 20.198839\n","the loss in 2600th batch is: 19.755924\n","the loss in 2800th batch is: 19.833849\n","the loss in 3000th batch is: 19.523977\n","the loss in 3200th batch is: 19.348454\n","the loss in 3400th batch is: 19.555401\n","the loss in 3600th batch is: 19.393848\n","the loss in 3800th batch is: 19.377436\n","the loss in 4000th batch is: 19.170742\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7120.200000\n","clicks hr ndcg @ 5 : 0.202205, 0.159973\n","purchase hr and ndcg @5 : 0.428110, 0.367579\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8176.400000\n","clicks hr ndcg @ 10 : 0.236611, 0.171136\n","purchase hr and ndcg @10 : 0.473109, 0.382233\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8746.200000\n","clicks hr ndcg @ 15 : 0.256429, 0.176382\n","purchase hr and ndcg @15 : 0.492112, 0.387318\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9133.800000\n","clicks hr ndcg @ 20 : 0.269871, 0.179561\n","purchase hr and ndcg @20 : 0.505199, 0.390415\n","#############################################################\n","the loss in 4200th batch is: 19.274532\n","the loss in 4400th batch is: 18.668928\n","the loss in 4600th batch is: 18.795815\n","the loss in 4800th batch is: 18.682856\n","the loss in 5000th batch is: 18.403643\n","the loss in 5200th batch is: 18.783825\n","the loss in 5400th batch is: 18.595343\n","the loss in 5600th batch is: 18.413715\n","the loss in 5800th batch is: 18.199163\n","the loss in 6000th batch is: 18.058132\n","the loss in 6200th batch is: 17.933851\n","the loss in 6400th batch is: 17.893776\n","the loss in 6600th batch is: 17.935223\n","the loss in 6800th batch is: 18.221563\n","the loss in 7000th batch is: 17.503094\n","the loss in 7200th batch is: 17.764078\n","the loss in 7400th batch is: 17.866444\n","the loss in 7600th batch is: 18.259136\n","the loss in 7800th batch is: 18.094797\n","the loss in 8000th batch is: 17.626608\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8919.800000\n","clicks hr ndcg @ 5 : 0.254104, 0.198811\n","purchase hr and ndcg @5 : 0.532987, 0.449653\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10295.200000\n","clicks hr ndcg @ 10 : 0.302107, 0.214369\n","purchase hr and ndcg @10 : 0.578164, 0.464276\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11021.400000\n","clicks hr ndcg @ 15 : 0.327838, 0.221193\n","purchase hr and ndcg @15 : 0.600394, 0.470148\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11523.400000\n","clicks hr ndcg @ 20 : 0.345614, 0.225393\n","purchase hr and ndcg @20 : 0.615812, 0.473788\n","#############################################################\n","the loss in 8200th batch is: 17.561850\n","the loss in 8400th batch is: 17.707905\n","the loss in 8600th batch is: 17.783516\n","the loss in 8800th batch is: 17.087578\n","the loss in 9000th batch is: 17.507832\n","the loss in 9200th batch is: 17.494768\n","the loss in 9400th batch is: 17.300892\n","the loss in 9600th batch is: 17.180582\n","the loss in 9800th batch is: 17.170797\n","the loss in 10000th batch is: 17.318483\n","the loss in 10200th batch is: 17.424294\n","the loss in 10400th batch is: 17.267353\n","the loss in 10600th batch is: 17.195208\n","the loss in 10800th batch is: 17.384527\n","the loss in 11000th batch is: 16.514675\n","the loss in 11200th batch is: 16.867762\n","the loss in 11400th batch is: 17.184908\n","the loss in 11600th batch is: 17.006161\n","the loss in 11800th batch is: 16.639362\n","the loss in 12000th batch is: 16.814871\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9427.400000\n","clicks hr ndcg @ 5 : 0.269854, 0.209043\n","purchase hr and ndcg @5 : 0.557906, 0.467619\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10930.400000\n","clicks hr ndcg @ 10 : 0.321514, 0.225788\n","purchase hr and ndcg @10 : 0.610613, 0.484916\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11721.000000\n","clicks hr ndcg @ 15 : 0.349058, 0.233081\n","purchase hr and ndcg @15 : 0.636787, 0.491854\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12229.000000\n","clicks hr ndcg @ 20 : 0.368030, 0.237564\n","purchase hr and ndcg @20 : 0.648261, 0.494579\n","#############################################################\n","the loss in 12200th batch is: 17.438530\n","the loss in 12400th batch is: 16.944389\n","the loss in 12600th batch is: 16.936535\n","the loss in 12800th batch is: 16.826712\n","the loss in 13000th batch is: 16.911263\n","the loss in 13200th batch is: 17.261461\n","the loss in 13400th batch is: 16.561945\n","the loss in 13600th batch is: 17.012674\n","the loss in 13800th batch is: 16.892706\n","the loss in 14000th batch is: 17.353308\n","the loss in 14200th batch is: 16.848289\n","the loss in 14400th batch is: 16.456640\n","the loss in 14600th batch is: 16.750113\n","the loss in 14800th batch is: 17.079832\n","the loss in 15000th batch is: 16.813234\n","the loss in 15200th batch is: 16.436127\n","the loss in 15400th batch is: 16.785894\n","the loss in 15600th batch is: 16.539278\n","the loss in 15800th batch is: 16.608982\n","the loss in 16000th batch is: 16.556808\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9567.800000\n","clicks hr ndcg @ 5 : 0.275170, 0.212196\n","purchase hr and ndcg @5 : 0.560774, 0.468660\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11205.600000\n","clicks hr ndcg @ 10 : 0.330026, 0.230003\n","purchase hr and ndcg @10 : 0.624238, 0.489513\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12040.000000\n","clicks hr ndcg @ 15 : 0.359569, 0.237834\n","purchase hr and ndcg @15 : 0.649875, 0.496330\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12606.800000\n","clicks hr ndcg @ 20 : 0.379686, 0.242593\n","purchase hr and ndcg @20 : 0.667085, 0.500407\n","#############################################################\n","the loss in 16200th batch is: 16.584265\n","the loss in 16400th batch is: 16.812941\n","the loss in 16600th batch is: 16.611691\n","the loss in 16800th batch is: 16.475845\n","the loss in 17000th batch is: 16.722082\n","the loss in 17200th batch is: 16.863886\n","the loss in 17400th batch is: 16.708569\n","the loss in 17600th batch is: 16.359152\n","the loss in 17800th batch is: 16.849157\n","the loss in 18000th batch is: 16.687069\n","the loss in 18200th batch is: 16.466339\n","the loss in 18400th batch is: 16.274664\n","the loss in 18600th batch is: 16.493902\n","the loss in 18800th batch is: 16.442585\n","the loss in 19000th batch is: 16.442259\n","the loss in 19200th batch is: 16.955410\n","the loss in 19400th batch is: 16.584890\n","the loss in 19600th batch is: 16.670868\n","the loss in 19800th batch is: 16.570625\n","the loss in 20000th batch is: 16.601772\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9650.800000\n","clicks hr ndcg @ 5 : 0.278375, 0.214269\n","purchase hr and ndcg @5 : 0.562209, 0.468601\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11289.600000\n","clicks hr ndcg @ 10 : 0.333274, 0.232074\n","purchase hr and ndcg @10 : 0.625672, 0.489214\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12156.200000\n","clicks hr ndcg @ 15 : 0.363851, 0.240181\n","purchase hr and ndcg @15 : 0.652743, 0.496405\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12731.800000\n","clicks hr ndcg @ 20 : 0.384387, 0.245032\n","purchase hr and ndcg @20 : 0.669774, 0.500426\n","#############################################################\n","the loss in 20200th batch is: 16.385124\n","the loss in 20400th batch is: 16.069874\n","the loss in 20600th batch is: 16.816423\n","the loss in 20800th batch is: 16.593649\n","the loss in 21000th batch is: 16.098652\n","the loss in 21200th batch is: 16.478361\n","the loss in 21400th batch is: 16.153896\n","the loss in 21600th batch is: 16.323717\n","the loss in 21800th batch is: 16.055969\n","the loss in 22000th batch is: 16.451160\n","the loss in 22200th batch is: 16.389441\n","the loss in 22400th batch is: 16.179480\n","the loss in 22600th batch is: 16.328159\n","the loss in 22800th batch is: 16.307985\n","the loss in 23000th batch is: 16.315773\n","the loss in 23200th batch is: 16.492714\n","the loss in 23400th batch is: 15.939920\n","the loss in 23600th batch is: 16.283678\n","the loss in 23800th batch is: 16.280674\n","the loss in 24000th batch is: 15.954538\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9731.800000\n","clicks hr ndcg @ 5 : 0.281622, 0.215731\n","purchase hr and ndcg @5 : 0.563105, 0.467245\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11339.600000\n","clicks hr ndcg @ 10 : 0.336393, 0.233495\n","purchase hr and ndcg @10 : 0.621549, 0.486292\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12218.800000\n","clicks hr ndcg @ 15 : 0.367167, 0.241646\n","purchase hr and ndcg @15 : 0.650054, 0.493832\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12811.000000\n","clicks hr ndcg @ 20 : 0.388241, 0.246624\n","purchase hr and ndcg @20 : 0.667802, 0.498001\n","#############################################################\n","the loss in 24200th batch is: 16.336063\n","the loss in 24400th batch is: 16.416613\n","the loss in 24600th batch is: 16.229229\n","the loss in 24800th batch is: 16.216333\n","the loss in 25000th batch is: 16.309975\n","the loss in 25200th batch is: 16.050972\n","the loss in 25400th batch is: 16.196966\n","the loss in 25600th batch is: 16.371496\n","the loss in 25800th batch is: 16.473610\n","the loss in 26000th batch is: 16.218464\n","the loss in 26200th batch is: 15.841446\n","the loss in 26400th batch is: 15.644944\n","the loss in 26600th batch is: 15.809289\n","the loss in 26800th batch is: 16.448439\n","the loss in 27000th batch is: 16.152006\n","the loss in 27200th batch is: 16.135233\n","the loss in 27400th batch is: 16.228508\n","the loss in 27600th batch is: 15.989818\n","the loss in 27800th batch is: 15.978020\n","the loss in 28000th batch is: 16.172216\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9658.200000\n","clicks hr ndcg @ 5 : 0.280443, 0.214339\n","purchase hr and ndcg @5 : 0.554858, 0.455097\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11282.800000\n","clicks hr ndcg @ 10 : 0.335589, 0.232210\n","purchase hr and ndcg @10 : 0.614736, 0.474636\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12193.800000\n","clicks hr ndcg @ 15 : 0.367295, 0.240607\n","purchase hr and ndcg @15 : 0.645034, 0.482662\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12798.600000\n","clicks hr ndcg @ 20 : 0.387882, 0.245471\n","purchase hr and ndcg @20 : 0.667085, 0.487856\n","#############################################################\n","the loss in 28200th batch is: 15.772528\n","the loss in 28400th batch is: 16.105915\n","the loss in 28600th batch is: 16.138226\n","the loss in 28800th batch is: 15.497684\n","the loss in 29000th batch is: 15.923941\n","the loss in 29200th batch is: 15.904749\n","the loss in 29400th batch is: 16.425020\n","the loss in 29600th batch is: 16.173283\n","the loss in 29800th batch is: 15.738711\n","the loss in 30000th batch is: 15.802854\n","the loss in 30200th batch is: 16.081953\n","the loss in 30400th batch is: 15.716026\n","the loss in 30600th batch is: 16.181433\n","the loss in 30800th batch is: 15.884045\n","the loss in 31000th batch is: 15.771426\n","the loss in 31200th batch is: 15.782402\n","the loss in 31400th batch is: 16.114349\n","the loss in 31600th batch is: 15.979408\n","the loss in 31800th batch is: 15.820609\n","the loss in 32000th batch is: 16.109482\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9603.000000\n","clicks hr ndcg @ 5 : 0.279323, 0.213119\n","purchase hr and ndcg @5 : 0.549659, 0.447825\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11239.400000\n","clicks hr ndcg @ 10 : 0.335316, 0.231265\n","purchase hr and ndcg @10 : 0.608103, 0.466795\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12100.800000\n","clicks hr ndcg @ 15 : 0.365287, 0.239200\n","purchase hr and ndcg @15 : 0.636787, 0.474409\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12688.400000\n","clicks hr ndcg @ 20 : 0.386378, 0.244183\n","purchase hr and ndcg @20 : 0.653639, 0.478398\n","#############################################################\n","the loss in 32200th batch is: 16.058058\n","the loss in 32400th batch is: 15.920479\n","the loss in 32600th batch is: 15.960597\n","the loss in 32800th batch is: 15.727261\n","the loss in 33000th batch is: 15.615209\n","the loss in 33200th batch is: 16.091623\n","the loss in 33400th batch is: 16.047073\n","the loss in 33600th batch is: 16.051907\n","the loss in 33800th batch is: 15.806787\n","the loss in 34000th batch is: 16.015984\n","the loss in 34200th batch is: 15.673601\n","the loss in 34400th batch is: 15.583883\n","the loss in 34600th batch is: 16.014366\n","the loss in 34800th batch is: 15.557914\n","the loss in 35000th batch is: 15.710104\n","the loss in 35200th batch is: 15.932443\n","the loss in 35400th batch is: 15.874140\n","the loss in 35600th batch is: 15.542262\n"]}]},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --CQL_alpha=1.0 --data=\"recommendation-system/Explore_CQL/Data/RR_data\""],"metadata":{"id":"RZeCX2BMObsd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cf325c9-c484-4c42-9aa3-7189528cfcf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-03 04:06:37.666411: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 04:06:38.769828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Using CQL loss.\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:191: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  self.seq = tf.compat.v1.layers.dropout(self.seq,\n","2023-05-03 04:06:40.988046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","2023-05-03 04:06:41.052021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:41.660466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:41.660775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 04:06:41.838750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 04:06:41.895160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-03 04:06:41.936289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:222: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","Using CQL loss.\n","2023-05-03 04:06:43.577375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 04:06:43.733282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 04:06:43.798087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 04:06:43.845725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-03 04:06:49.566246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:49.566645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:49.566896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:52.320719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:52.321001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:52.321234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 04:06:52.321395: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-03 04:06:52.321440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14518 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-05-03 04:06:52.375219: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n","2023-05-03 04:06:57.051176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.800000\n","clicks hr ndcg @ 5 : 0.000077, 0.000038\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3.600000\n","clicks hr ndcg @ 10 : 0.000154, 0.000062\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.600000\n","clicks hr ndcg @ 15 : 0.000197, 0.000073\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8.800000\n","clicks hr ndcg @ 20 : 0.000291, 0.000095\n","purchase hr and ndcg @20 : 0.000359, 0.000083\n","#############################################################\n","the loss in 200th batch is: 34.109909\n","the loss in 400th batch is: 32.893181\n","the loss in 600th batch is: 31.604019\n","the loss in 800th batch is: 31.062632\n","the loss in 1000th batch is: 30.716614\n","the loss in 1200th batch is: 30.225048\n","the loss in 1400th batch is: 29.739384\n","the loss in 1600th batch is: 29.544001\n","the loss in 1800th batch is: 28.901863\n","the loss in 2000th batch is: 28.950611\n","the loss in 2200th batch is: 28.916140\n","the loss in 2400th batch is: 28.713760\n","the loss in 2600th batch is: 28.535400\n","the loss in 2800th batch is: 28.365879\n","the loss in 3000th batch is: 28.462418\n","the loss in 3200th batch is: 28.483559\n","the loss in 3400th batch is: 28.679365\n","the loss in 3600th batch is: 28.547771\n","the loss in 3800th batch is: 28.128408\n","the loss in 4000th batch is: 28.423798\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 197.400000\n","clicks hr ndcg @ 5 : 0.005529, 0.003432\n","purchase hr and ndcg @5 : 0.012191, 0.008566\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 303.600000\n","clicks hr ndcg @ 10 : 0.009127, 0.004579\n","purchase hr and ndcg @10 : 0.016135, 0.009795\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 421.000000\n","clicks hr ndcg @ 15 : 0.012819, 0.005552\n","purchase hr and ndcg @15 : 0.021692, 0.011261\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 489.600000\n","clicks hr ndcg @ 20 : 0.015024, 0.006073\n","purchase hr and ndcg @20 : 0.024740, 0.011984\n","#############################################################\n","the loss in 4200th batch is: 28.472832\n","the loss in 4400th batch is: 28.166431\n","the loss in 4600th batch is: 28.231762\n","the loss in 4800th batch is: 28.291235\n","the loss in 5000th batch is: 28.385468\n","the loss in 5200th batch is: 28.168312\n","the loss in 5400th batch is: 28.099899\n","the loss in 5600th batch is: 28.257746\n","the loss in 5800th batch is: 28.394611\n","the loss in 6000th batch is: 28.059767\n","the loss in 6200th batch is: 28.473930\n","the loss in 6400th batch is: 28.064510\n","the loss in 6600th batch is: 28.151045\n","the loss in 6800th batch is: 27.927477\n","the loss in 7000th batch is: 28.168114\n","the loss in 7200th batch is: 28.044460\n","the loss in 7400th batch is: 27.966293\n","the loss in 7600th batch is: 27.872988\n","the loss in 7800th batch is: 28.080173\n","the loss in 8000th batch is: 28.120197\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1026.600000\n","clicks hr ndcg @ 5 : 0.029936, 0.020979\n","purchase hr and ndcg @5 : 0.058444, 0.044705\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 1422.800000\n","clicks hr ndcg @ 10 : 0.042123, 0.024925\n","purchase hr and ndcg @10 : 0.078343, 0.051149\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 1708.200000\n","clicks hr ndcg @ 15 : 0.051113, 0.027293\n","purchase hr and ndcg @15 : 0.091789, 0.054719\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 1974.600000\n","clicks hr ndcg @ 20 : 0.059249, 0.029217\n","purchase hr and ndcg @20 : 0.105414, 0.057938\n","#############################################################\n","the loss in 8200th batch is: 28.230885\n","the loss in 8400th batch is: 28.011765\n","the loss in 8600th batch is: 28.087971\n","the loss in 8800th batch is: 27.770559\n","the loss in 9000th batch is: 27.686543\n","the loss in 9200th batch is: 28.208717\n","the loss in 9400th batch is: 28.080027\n","the loss in 9600th batch is: 27.955908\n","the loss in 9800th batch is: 27.812254\n","the loss in 10000th batch is: 28.018229\n","the loss in 10200th batch is: 28.046499\n","the loss in 10400th batch is: 27.902397\n","the loss in 10600th batch is: 27.327501\n","the loss in 10800th batch is: 27.516863\n","the loss in 11000th batch is: 27.567802\n","the loss in 11200th batch is: 27.856560\n","the loss in 11400th batch is: 27.148907\n","the loss in 11600th batch is: 26.918514\n","the loss in 11800th batch is: 27.218822\n","the loss in 12000th batch is: 27.505070\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4585.000000\n","clicks hr ndcg @ 5 : 0.131222, 0.101790\n","purchase hr and ndcg @5 : 0.271423, 0.225664\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5437.200000\n","clicks hr ndcg @ 10 : 0.158963, 0.110773\n","purchase hr and ndcg @10 : 0.307816, 0.237439\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5967.200000\n","clicks hr ndcg @ 15 : 0.175969, 0.115276\n","purchase hr and ndcg @15 : 0.331481, 0.243714\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6352.200000\n","clicks hr ndcg @ 20 : 0.188446, 0.118221\n","purchase hr and ndcg @20 : 0.348153, 0.247645\n","#############################################################\n","the loss in 12200th batch is: 27.652805\n","the loss in 12400th batch is: 27.534256\n","the loss in 12600th batch is: 27.463503\n","the loss in 12800th batch is: 26.980370\n","the loss in 13000th batch is: 26.490124\n","the loss in 13200th batch is: 27.182983\n","the loss in 13400th batch is: 27.495928\n","the loss in 13600th batch is: 26.568510\n","the loss in 13800th batch is: 27.136835\n","the loss in 14000th batch is: 27.518848\n","the loss in 14200th batch is: 27.210154\n","the loss in 14400th batch is: 26.803932\n","the loss in 14600th batch is: 27.317400\n","the loss in 14800th batch is: 27.025578\n","the loss in 15000th batch is: 27.077408\n","the loss in 15200th batch is: 26.142796\n","the loss in 15400th batch is: 27.290045\n","the loss in 15600th batch is: 26.868000\n","the loss in 15800th batch is: 26.404026\n","the loss in 16000th batch is: 26.506294\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7118.600000\n","clicks hr ndcg @ 5 : 0.203931, 0.161290\n","purchase hr and ndcg @5 : 0.420581, 0.353515\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8245.200000\n","clicks hr ndcg @ 10 : 0.241302, 0.173396\n","purchase hr and ndcg @10 : 0.465758, 0.368219\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8879.200000\n","clicks hr ndcg @ 15 : 0.263094, 0.179166\n","purchase hr and ndcg @15 : 0.487989, 0.374080\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9329.400000\n","clicks hr ndcg @ 20 : 0.278956, 0.182915\n","purchase hr and ndcg @20 : 0.502151, 0.377440\n","#############################################################\n","the loss in 16200th batch is: 25.713924\n","the loss in 16400th batch is: 25.873781\n","the loss in 16600th batch is: 26.577068\n","the loss in 16800th batch is: 25.978577\n","the loss in 17000th batch is: 26.446220\n","the loss in 17200th batch is: 25.952503\n","the loss in 17400th batch is: 26.494848\n","the loss in 17600th batch is: 26.029768\n","the loss in 17800th batch is: 26.654362\n","the loss in 18000th batch is: 25.698471\n","the loss in 18200th batch is: 26.023270\n","the loss in 18400th batch is: 25.680689\n","the loss in 18600th batch is: 25.316334\n","the loss in 18800th batch is: 26.122883\n","the loss in 19000th batch is: 26.476370\n","the loss in 19200th batch is: 25.746380\n","the loss in 19400th batch is: 25.613577\n","the loss in 19600th batch is: 26.361961\n","the loss in 19800th batch is: 25.869953\n","the loss in 20000th batch is: 24.997103\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8235.600000\n","clicks hr ndcg @ 5 : 0.238542, 0.188455\n","purchase hr and ndcg @5 : 0.475619, 0.409799\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9515.800000\n","clicks hr ndcg @ 10 : 0.282391, 0.202688\n","purchase hr and ndcg @10 : 0.521155, 0.424602\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10263.400000\n","clicks hr ndcg @ 15 : 0.307200, 0.209262\n","purchase hr and ndcg @15 : 0.551094, 0.432564\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10768.000000\n","clicks hr ndcg @ 20 : 0.324574, 0.213367\n","purchase hr and ndcg @20 : 0.568663, 0.436735\n","#############################################################\n","the loss in 20200th batch is: 25.878464\n","the loss in 20400th batch is: 25.652487\n","the loss in 20600th batch is: 25.422562\n","the loss in 20800th batch is: 25.638937\n","the loss in 21000th batch is: 25.994251\n","the loss in 21200th batch is: 25.109810\n","the loss in 21400th batch is: 25.742361\n","the loss in 21600th batch is: 25.099554\n","the loss in 21800th batch is: 25.715256\n","the loss in 22000th batch is: 25.605610\n","the loss in 22200th batch is: 25.812727\n","the loss in 22400th batch is: 24.819599\n","the loss in 22600th batch is: 25.542465\n","the loss in 22800th batch is: 25.082624\n","the loss in 23000th batch is: 25.397411\n","the loss in 23200th batch is: 25.234266\n","the loss in 23400th batch is: 25.594975\n","the loss in 23600th batch is: 25.017256\n","the loss in 23800th batch is: 25.716837\n","the loss in 24000th batch is: 25.010303\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8858.600000\n","clicks hr ndcg @ 5 : 0.256745, 0.203519\n","purchase hr and ndcg @5 : 0.510936, 0.435101\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10257.600000\n","clicks hr ndcg @ 10 : 0.303833, 0.218787\n","purchase hr and ndcg @10 : 0.564181, 0.452338\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11017.800000\n","clicks hr ndcg @ 15 : 0.329992, 0.225714\n","purchase hr and ndcg @15 : 0.590714, 0.459395\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11532.000000\n","clicks hr ndcg @ 20 : 0.347648, 0.229886\n","purchase hr and ndcg @20 : 0.608820, 0.463679\n","#############################################################\n","the loss in 24200th batch is: 25.063847\n","the loss in 24400th batch is: 24.702555\n","the loss in 24600th batch is: 24.838894\n","the loss in 24800th batch is: 25.166409\n","the loss in 25000th batch is: 25.239838\n","the loss in 25200th batch is: 25.196939\n","the loss in 25400th batch is: 25.108536\n","the loss in 25600th batch is: 24.788324\n","the loss in 25800th batch is: 24.690155\n","the loss in 26000th batch is: 25.332367\n","the loss in 26200th batch is: 24.829414\n","the loss in 26400th batch is: 24.949938\n","the loss in 26600th batch is: 24.882008\n","the loss in 26800th batch is: 25.192696\n","the loss in 27000th batch is: 24.567209\n","the loss in 27200th batch is: 24.896492\n","the loss in 27400th batch is: 24.899340\n","the loss in 27600th batch is: 24.784653\n","the loss in 27800th batch is: 24.438831\n","the loss in 28000th batch is: 24.848722\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9273.000000\n","clicks hr ndcg @ 5 : 0.268128, 0.211256\n","purchase hr and ndcg @5 : 0.537469, 0.455685\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10692.200000\n","clicks hr ndcg @ 10 : 0.316763, 0.227020\n","purchase hr and ndcg @10 : 0.587845, 0.472084\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11462.200000\n","clicks hr ndcg @ 15 : 0.343768, 0.234172\n","purchase hr and ndcg @15 : 0.612585, 0.478624\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12001.200000\n","clicks hr ndcg @ 20 : 0.362398, 0.238576\n","purchase hr and ndcg @20 : 0.631051, 0.482988\n","#############################################################\n","the loss in 28200th batch is: 24.261665\n","the loss in 28400th batch is: 24.556273\n","the loss in 28600th batch is: 25.224937\n","the loss in 28800th batch is: 24.506924\n","the loss in 29000th batch is: 24.868532\n","the loss in 29200th batch is: 25.020201\n","the loss in 29400th batch is: 24.915995\n","the loss in 29600th batch is: 24.664528\n","the loss in 29800th batch is: 24.951546\n","the loss in 30000th batch is: 24.399441\n","the loss in 30200th batch is: 24.245758\n","the loss in 30400th batch is: 24.619539\n","the loss in 30600th batch is: 24.450302\n","the loss in 30800th batch is: 24.931133\n","the loss in 31000th batch is: 24.377224\n","the loss in 31200th batch is: 24.996967\n","the loss in 31400th batch is: 24.692493\n","the loss in 31600th batch is: 24.573507\n","the loss in 31800th batch is: 24.519957\n","the loss in 32000th batch is: 24.395008\n","#############################################################\n","total clicks: 117015, total purchase:5578\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9380.400000\n","clicks hr ndcg @ 5 : 0.272247, 0.214696\n","purchase hr and ndcg @5 : 0.539441, 0.457883\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10890.200000\n","clicks hr ndcg @ 10 : 0.323343, 0.231283\n","purchase hr and ndcg @10 : 0.595733, 0.476175\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11707.200000\n","clicks hr ndcg @ 15 : 0.351801, 0.238819\n","purchase hr and ndcg @15 : 0.622804, 0.483355\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12223.800000\n","clicks hr ndcg @ 20 : 0.370756, 0.243297\n","purchase hr and ndcg @20 : 0.635891, 0.486451\n","#############################################################\n","the loss in 32200th batch is: 24.495441\n","the loss in 32400th batch is: 24.356373\n","the loss in 32600th batch is: 25.073233\n","the loss in 32800th batch is: 24.453476\n","the loss in 33000th batch is: 24.554516\n","the loss in 33200th batch is: 24.759563\n","the loss in 33400th batch is: 24.518721\n","the loss in 33600th batch is: 24.252485\n","the loss in 33800th batch is: 24.129234\n","the loss in 34000th batch is: 24.284164\n","the loss in 34200th batch is: 24.856285\n","the loss in 34400th batch is: 24.289246\n","the loss in 34600th batch is: 24.146049\n","the loss in 34800th batch is: 24.534307\n","the loss in 35000th batch is: 24.264326\n","the loss in 35200th batch is: 24.255821\n","the loss in 35400th batch is: 24.393747\n","the loss in 35600th batch is: 23.992428\n","the loss in 35800th batch is: 24.139805\n","the loss in 36000th batch is: 24.121979\n"]}]},{"cell_type":"markdown","source":["## H&M"],"metadata":{"id":"B0g9xSjkMdme"}},{"cell_type":"markdown","source":["### Prepare the Data"],"metadata":{"id":"Ijoc7SsgNR-G"}},{"cell_type":"code","source":["# Download the data\n","!wget https://aipi590.s3.amazonaws.com/transactions_train.csv -P \"recommendation-system/Explore_CQL/Data/HM_data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyzTG8LUNKSu","outputId":"d99b3930-84e4-4519-ed86-656b6418fdef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-02 20:34:42--  https://aipi590.s3.amazonaws.com/transactions_train.csv\n","Resolving aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)... 52.217.228.57, 3.5.29.19, 54.231.204.217, ...\n","Connecting to aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)|52.217.228.57|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3488002253 (3.2G) [text/csv]\n","Saving to: ‘recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’\n","\n","transactions_train. 100%[===================>]   3.25G  13.1MB/s    in 4m 17s  \n","\n","2023-05-02 20:39:01 (12.9 MB/s) - ‘recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’ saved [3488002253/3488002253]\n","\n"]}]},{"cell_type":"code","source":["# Preprocess the data\n","!python \"recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer_HM.py\" --data=\"recommendation-system/Explore_CQL/Data/HM_data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_tHGRfsPGcm","outputId":"e9eb99da-6f74-40db-ce11-4ab4e06da5d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start reading all transaction data ...\n","Finish reading in 00:00:28\n","\n","Filter and save all valid sampled data\n","Index(['timestamp', 'session_id', 'item_id', 'price', 'sales_channel_id'], dtype='object')\n","\n","Start counting popularity ...\n","13040912it [08:15, 26313.18it/s]\n","Popularity finished in 00:08:15\n","\n","Start spliting into train, val, test data ...\n","\n","           Generate Replay Buffer:\n","                Total Session Size : 1245612\n","                     Train:      871928 ids | 9124752 actions\n","                     Validation: 249122 ids | 2611174 actions\n","                     Test:       124562 ids | 1304986 actions\n","                     \n","                Random : True\n","                Random Seed : 1234\n","                Format : paper\n","    \n","                Total session id number : 1245612\n","                Total item id number  : 96222\n","    \n","Generating training replay buffer\n","100% 608701/608701 [09:51<00:00, 1029.08it/s]\n"]}]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"74DxOJZWN9u2"}},{"cell_type":"markdown","source":["#### Without CQL Loss"],"metadata":{"id":"YrsydWYDOHuu"}},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --data=\"recommendation-system/Explore_CQL/Data/HM_data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hXhTh30OqIT","outputId":"41ed36f2-417f-43a5-8bd8-347b3d2a388c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-02 21:00:17.915279: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-05-02 21:00:17.970957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-02 21:00:19.027661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Not using CQL loss\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:191: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  self.seq = tf.compat.v1.layers.dropout(self.seq,\n","2023-05-02 21:00:21.143740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 21:00:21.789475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 21:00:21.846570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n","  outputs = tf.compat.v1.layers.conv1d(**params)\n","/content/recommendation-system/Explore_CQL/DLR2/src/SASRecModules_v2.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n","2023-05-02 21:00:21.887848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n","\t [[{{node Placeholder}}]]\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py:222: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","Not using CQL loss\n","2023-05-02 21:00:23.437882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 21:00:23.598925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 21:00:23.660654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 21:00:23.710274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n","\t [[{{node Placeholder_1}}]]\n","2023-05-02 21:00:52.143354: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-02 21:00:52.143433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38286 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","2023-05-02 21:00:52.193183: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n","2023-05-02 21:00:57.343115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"]}]},{"cell_type":"markdown","source":["#### With CQL Loss"],"metadata":{"id":"TVxR4rNUOHuu"}},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --CQL_alpha=0.5 --data=\"recommendation-system/Explore_CQL/Data/HM_data\""],"metadata":{"id":"RQ2TA8FuOpHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python \"recommendation-system/Explore_CQL/DLR2/src/SNQN_v2.py\" --model=SASRec --epoch=10 --CQL_alpha=1.0 --data=\"recommendation-system/Explore_CQL/Data/HM_data\""],"metadata":{"id":"Qt9KNKAROpHM"},"execution_count":null,"outputs":[]}]}
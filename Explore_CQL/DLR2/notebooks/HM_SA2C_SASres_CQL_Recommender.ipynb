{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szheng3/recommendation-system/blob/main/Explore_CQL/DLR2/notebooks/HM_SA2C_SASres_CQL_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# SA2C-SASRec Recommender on H&M Data with Conservative Q-learning\n",
        "\n",
        "In this notebook we train an SA2C_SASrec model without and with CQL to train for recommendation on H&M dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgK2r88Mmkd",
        "outputId": "1509b1e0-2e4f-417b-ddb9-119debb210f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'recommendation-system'...\n",
            "remote: Enumerating objects: 1622, done.\u001b[K\n",
            "remote: Counting objects: 100% (403/403), done.\u001b[K\n",
            "remote: Compressing objects: 100% (216/216), done.\u001b[K\n",
            "remote: Total 1622 (delta 226), reused 331 (delta 186), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1622/1622), 11.71 MiB | 9.93 MiB/s, done.\n",
            "Resolving deltas: 100% (856/856), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the git repository\n",
        "!git clone https://github.com/szheng3/recommendation-system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3pkxR1AsDW",
        "outputId": "2eb28aaf-0446-493b-882c-13ff30099d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting d3rlpy\n",
            "  Downloading d3rlpy-1.1.1.tar.gz (317 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.6/317.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (1.2.2)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (4.65.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (3.8.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (0.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (8.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (4.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (1.10.1)\n",
            "Collecting structlog\n",
            "  Downloading structlog-23.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->d3rlpy) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->d3rlpy) (2.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->d3rlpy) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->d3rlpy) (1.2.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->d3rlpy) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->d3rlpy) (23.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->d3rlpy) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->d3rlpy) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->d3rlpy) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->d3rlpy) (1.3.0)\n",
            "Building wheels for collected packages: d3rlpy\n",
            "  Building wheel for d3rlpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for d3rlpy: filename=d3rlpy-1.1.1-cp310-cp310-linux_x86_64.whl size=1257776 sha256=54852be99a426baac3ae8bd79c6767e7cd7c28089d96301f8a9d9c8c3413fc6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/c4/aab790777bd0d1358b9e8cc391621a4e0e2b10e7cd03406ad6\n",
            "Successfully built d3rlpy\n",
            "Installing collected packages: trfl, tensorboardX, structlog, colorama, d3rlpy\n",
            "Successfully installed colorama-0.4.6 d3rlpy-1.1.1 structlog-23.1.0 tensorboardX-2.6 trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# installing missing libraries (specifically for google colab)\n",
        "!pip install trfl d3rlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the H&M Dataset transaction log file from AWS S3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7SMHfSMiHI",
        "outputId": "30a2bd56-a792-4454-e1b5-142e7ccef578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-03 16:29:52--  https://aipi590.s3.amazonaws.com/transactions_train.csv\n",
            "Resolving aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)... 52.216.237.43, 52.217.47.52, 3.5.3.139, ...\n",
            "Connecting to aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)|52.216.237.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3488002253 (3.2G) [text/csv]\n",
            "Saving to: ‘/content/recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’\n",
            "\n",
            "transactions_train. 100%[===================>]   3.25G  12.7MB/s    in 4m 30s  \n",
            "\n",
            "2023-05-03 16:34:23 (12.3 MB/s) - ‘/content/recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’ saved [3488002253/3488002253]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# downloading the \"transactions_train.csv\" datafile from the H&M Dataset\n",
        "!wget https://aipi590.s3.amazonaws.com/transactions_train.csv -P \"/content/recommendation-system/Explore_CQL/Data/HM_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Run the \"gen_replay_buffer.py\" script to pre-process data and generate replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-MWI_XktTHX",
        "outputId": "68cc9e83-aaf3-4178-ad2d-85793d22fd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start reading all transaction data ...\n",
            "Finish reading in 00:00:25\n",
            "\n",
            "Filter and save all valid sampled data\n",
            "/content/recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer_HM.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sampled_sessions['valid_session'] = sampled_sessions.session_id.map(sampled_sessions.groupby('session_id')['item_id'].size() > 2)\n",
            "Index(['timestamp', 'session_id', 'item_id', 'price', 'sales_channel_id'], dtype='object')\n",
            "\n",
            "Start counting popularity ...\n",
            "527547it [00:18, 29121.12it/s]\n",
            "Popularity finished in 00:00:18\n",
            "\n",
            "Start spliting into train, val, test data ...\n",
            "\n",
            "           Generate Replay Buffer:\n",
            "                Total Session Size : 50000\n",
            "                     Train:      35000 ids | 369017 actions\n",
            "                     Validation: 10000 ids | 105214 actions\n",
            "                     Test:       5000 ids | 53316 actions\n",
            "                     \n",
            "                Random : True\n",
            "                Random Seed : 1234\n",
            "                Format : paper\n",
            "    \n",
            "                Total session id number : 1245612\n",
            "                Total item id number  : 96222\n",
            "    \n",
            "Generating training replay buffer\n",
            "100% 24492/24492 [00:21<00:00, 1123.98it/s]\n"
          ]
        }
      ],
      "source": [
        "# Executing the python script \"gen_replay_buffer\" to sample the given H&M dataset\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer_HM.py\" --size=50000 --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SASRec-SNQN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "96ea1501-8ac0-4266-c502-3b40bb9b0556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 17:29:26.218670: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 17:29:27.178913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not using CQL loss\n",
            "2023-05-03 17:29:28.982745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 17:29:29.013806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:29.045450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:29.045728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:29.192898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 17:29:29.247294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 17:29:29.285316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "Not using CQL loss\n",
            "2023-05-03 17:29:32.032276: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 17:29:32.181788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 17:29:32.239095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 17:29:32.280862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 17:29:36.511202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:36.511502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:36.511667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:37.405166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:37.405427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:37.405619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 17:29:37.405746: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 17:29:37.405781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 17:29:37.490655: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "epoch 1\n",
            "2023-05-03 17:29:39.476611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 11.634867\n",
            "the loss in 400th batch is: 11.350228\n",
            "the loss in 600th batch is: 10.913260\n",
            "the loss in 800th batch is: 10.628702\n",
            "the loss in 1000th batch is: 10.995032\n",
            "the loss in 1200th batch is: 10.581564\n",
            "the loss in 1400th batch is: 10.624712\n",
            "epoch 2\n",
            "the loss in 1600th batch is: 10.484423\n",
            "the loss in 1800th batch is: 10.637362\n",
            "the loss in 2000th batch is: 10.410869\n",
            "the loss in 2200th batch is: 10.267560\n",
            "the loss in 2400th batch is: 10.326537\n",
            "the loss in 2600th batch is: 10.196552\n",
            "the loss in 2800th batch is: 9.989426\n",
            "epoch 3\n",
            "the loss in 3000th batch is: 9.814780\n",
            "the loss in 3200th batch is: 9.827284\n",
            "the loss in 3400th batch is: 9.856316\n",
            "the loss in 3600th batch is: 9.754845\n",
            "the loss in 3800th batch is: 9.548232\n",
            "the loss in 4000th batch is: 9.632267\n",
            "the loss in 4200th batch is: 9.712040\n",
            "epoch 4\n",
            "the loss in 4400th batch is: 9.606958\n",
            "the loss in 4600th batch is: 9.453138\n",
            "the loss in 4800th batch is: 9.296732\n",
            "the loss in 5000th batch is: 9.292400\n",
            "the loss in 5200th batch is: 9.137605\n",
            "the loss in 5400th batch is: 9.199846\n",
            "the loss in 5600th batch is: 9.455669\n",
            "epoch 5\n",
            "the loss in 5800th batch is: 9.323198\n",
            "the loss in 6000th batch is: 8.972219\n",
            "the loss in 6200th batch is: 8.851048\n",
            "the loss in 6400th batch is: 8.821441\n",
            "the loss in 6600th batch is: 9.040178\n",
            "the loss in 6800th batch is: 8.743570\n",
            "the loss in 7000th batch is: 8.784703\n",
            "the loss in 7200th batch is: 8.709229\n",
            "epoch 6\n",
            "the loss in 7400th batch is: 8.852898\n",
            "the loss in 7600th batch is: 8.634949\n",
            "the loss in 7800th batch is: 8.731192\n",
            "the loss in 8000th batch is: 8.525899\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6335.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.060211, 0.048281\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7447.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.070780, 0.051700\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8167.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.077623, 0.053511\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8734.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.083012, 0.054784\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 8.527321\n",
            "the loss in 8400th batch is: 8.505582\n",
            "the loss in 8600th batch is: 8.399775\n",
            "epoch 7\n",
            "the loss in 8800th batch is: 8.285666\n",
            "the loss in 9000th batch is: 8.210335\n",
            "the loss in 9200th batch is: 8.164775\n",
            "the loss in 9400th batch is: 8.007363\n",
            "the loss in 9600th batch is: 8.282457\n",
            "the loss in 9800th batch is: 7.980467\n",
            "the loss in 10000th batch is: 7.960895\n",
            "epoch 8\n",
            "the loss in 10200th batch is: 7.775649\n",
            "the loss in 10400th batch is: 7.839638\n",
            "the loss in 10600th batch is: 7.763626\n",
            "the loss in 10800th batch is: 7.602288\n",
            "the loss in 11000th batch is: 8.024832\n",
            "the loss in 11200th batch is: 7.540915\n",
            "the loss in 11400th batch is: 7.937374\n",
            "epoch 9\n",
            "the loss in 11600th batch is: 7.892024\n",
            "the loss in 11800th batch is: 7.842235\n",
            "the loss in 12000th batch is: 7.908516\n",
            "the loss in 12200th batch is: 7.619537\n",
            "the loss in 12400th batch is: 7.348732\n",
            "the loss in 12600th batch is: 7.575629\n",
            "the loss in 12800th batch is: 7.052311\n",
            "epoch 10\n",
            "the loss in 13000th batch is: 7.481600\n",
            "the loss in 13200th batch is: 7.234248\n",
            "the loss in 13400th batch is: 7.041363\n",
            "the loss in 13600th batch is: 7.296231\n",
            "the loss in 13800th batch is: 7.177532\n",
            "the loss in 14000th batch is: 6.926920\n",
            "the loss in 14200th batch is: 6.621829\n",
            "the loss in 14400th batch is: 6.446052\n",
            "epoch 11\n",
            "the loss in 14600th batch is: 6.897193\n",
            "the loss in 14800th batch is: 7.098441\n",
            "the loss in 15000th batch is: 6.846033\n",
            "the loss in 15200th batch is: 4.550951\n",
            "the loss in 15400th batch is: 4.303862\n",
            "the loss in 15600th batch is: 4.284745\n",
            "the loss in 15800th batch is: 4.487946\n",
            "epoch 12\n",
            "the loss in 16000th batch is: 4.466065\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6716.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.063832, 0.049877\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8020.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.076226, 0.053888\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8785.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.083496, 0.055813\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9371.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.089066, 0.057128\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 4.339902\n",
            "the loss in 16400th batch is: 4.383713\n",
            "the loss in 16600th batch is: 4.347446\n",
            "the loss in 16800th batch is: 4.261675\n",
            "the loss in 17000th batch is: 4.247330\n",
            "the loss in 17200th batch is: 4.229024\n",
            "epoch 13\n",
            "the loss in 17400th batch is: 4.514649\n",
            "the loss in 17600th batch is: 4.513936\n",
            "the loss in 17800th batch is: 4.442537\n",
            "the loss in 18000th batch is: 4.556040\n",
            "the loss in 18200th batch is: 4.203827\n",
            "the loss in 18400th batch is: 4.332476\n",
            "the loss in 18600th batch is: 4.604328\n",
            "epoch 14\n",
            "the loss in 18800th batch is: 4.162148\n",
            "the loss in 19000th batch is: 4.197450\n",
            "the loss in 19200th batch is: 4.195917\n",
            "the loss in 19400th batch is: 4.279234\n",
            "the loss in 19600th batch is: 4.342351\n",
            "the loss in 19800th batch is: 4.149077\n",
            "the loss in 20000th batch is: 4.286149\n",
            "epoch 15\n",
            "the loss in 20200th batch is: 4.701634\n",
            "the loss in 20400th batch is: 4.389383\n",
            "the loss in 20600th batch is: 4.385950\n",
            "the loss in 20800th batch is: 4.337000\n",
            "the loss in 21000th batch is: 4.212954\n",
            "the loss in 21200th batch is: 4.017244\n",
            "the loss in 21400th batch is: 4.057098\n",
            "the loss in 21600th batch is: 4.218106\n",
            "epoch 16\n",
            "the loss in 21800th batch is: 4.026277\n",
            "the loss in 22000th batch is: 4.128913\n",
            "the loss in 22200th batch is: 4.048771\n",
            "the loss in 22400th batch is: 4.025825\n",
            "the loss in 22600th batch is: 3.916730\n",
            "the loss in 22800th batch is: 4.158772\n",
            "the loss in 23000th batch is: 4.018473\n",
            "epoch 17\n",
            "the loss in 23200th batch is: 4.165451\n",
            "the loss in 23400th batch is: 3.912009\n",
            "the loss in 23600th batch is: 4.147261\n",
            "the loss in 23800th batch is: 3.976699\n",
            "the loss in 24000th batch is: 3.763265\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6682.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.063509, 0.048519\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8036.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.076378, 0.052671\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8843.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.084048, 0.054700\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9437.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.089693, 0.056034\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 4.099465\n",
            "the loss in 24400th batch is: 4.159757\n",
            "epoch 18\n",
            "the loss in 24600th batch is: 3.810270\n",
            "the loss in 24800th batch is: 3.872186\n",
            "the loss in 25000th batch is: 3.732178\n",
            "the loss in 25200th batch is: 4.006527\n",
            "the loss in 25400th batch is: 3.699270\n",
            "the loss in 25600th batch is: 3.715601\n",
            "the loss in 25800th batch is: 3.845424\n",
            "epoch 19\n",
            "the loss in 26000th batch is: 3.604817\n",
            "the loss in 26200th batch is: 3.886000\n",
            "the loss in 26400th batch is: 3.650218\n",
            "the loss in 26600th batch is: 3.773880\n",
            "the loss in 26800th batch is: 3.388217\n",
            "the loss in 27000th batch is: 3.441770\n",
            "the loss in 27200th batch is: 3.561168\n",
            "epoch 20\n",
            "the loss in 27400th batch is: 3.660392\n",
            "the loss in 27600th batch is: 3.679478\n",
            "the loss in 27800th batch is: 3.678650\n",
            "the loss in 28000th batch is: 3.544451\n",
            "the loss in 28200th batch is: 3.568707\n",
            "the loss in 28400th batch is: 3.879091\n",
            "the loss in 28600th batch is: 3.518944\n",
            "the loss in 28800th batch is: 3.554358\n",
            "Training completed...\n",
            "Evaluating test dataset...\n",
            "\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:53316\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3349.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.062814, 0.046395\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 4115.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.077181, 0.051043\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4546.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.085265, 0.053180\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4856.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.091080, 0.054552\n",
            "#############################################################\n"
          ]
        }
      ],
      "source": [
        "# Executing the python script \"SA2C_v3.py\" to train a SA2C-SASrec model on the sampled data and evaluate it on validation data using HR (hit rate) and NDCG metrics for different values of k\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/SA2C_v3_5.py\" --model=SASRec --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data/\" --epoch=20"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vZxRqVldJUwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the python script \"SA2C_v3.py\" to train a SA2C-SASrec model on the sampled data with CQL and evaluate it on validation data using HR (hit rate) and NDCG metrics for different values of k\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/SA2C_v3_5.py\" --model=SASRec --CQL_alpha=0.5 --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data/\" --epoch=20"
      ],
      "metadata": {
        "id": "M5NVOfakncxU",
        "outputId": "987d9556-a70a-4727-cebb-f60eb9af003c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 19:51:53.491696: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 19:51:54.472424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using CQL loss.\n",
            "2023-05-03 19:51:56.339403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 19:51:56.371509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:51:56.405083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:51:56.405332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:51:56.556898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 19:51:56.610827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 19:51:56.649561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "Using CQL loss.\n",
            "2023-05-03 19:51:59.542369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 19:51:59.689261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 19:51:59.746263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 19:51:59.787486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 19:52:04.101338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.101648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.101823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.985482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.985751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.985926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 19:52:04.986057: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 19:52:04.986093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 19:52:05.076728: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "epoch 1\n",
            "2023-05-03 19:52:07.107910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 23.326099\n",
            "the loss in 400th batch is: 22.056408\n",
            "the loss in 600th batch is: 21.390060\n",
            "the loss in 800th batch is: 21.192415\n",
            "the loss in 1000th batch is: 20.565327\n",
            "the loss in 1200th batch is: 19.901632\n",
            "the loss in 1400th batch is: 19.757977\n",
            "epoch 2\n",
            "the loss in 1600th batch is: 19.501867\n",
            "the loss in 1800th batch is: 19.718819\n",
            "the loss in 2000th batch is: 19.706680\n",
            "the loss in 2200th batch is: 19.617163\n",
            "the loss in 2400th batch is: 19.541677\n",
            "the loss in 2600th batch is: 19.450390\n",
            "the loss in 2800th batch is: 19.335985\n",
            "epoch 3\n",
            "the loss in 3000th batch is: 19.508034\n",
            "the loss in 3200th batch is: 19.191360\n",
            "the loss in 3400th batch is: 19.406961\n",
            "the loss in 3600th batch is: 19.419636\n",
            "the loss in 3800th batch is: 19.125883\n",
            "the loss in 4000th batch is: 19.192738\n",
            "the loss in 4200th batch is: 19.033594\n",
            "epoch 4\n",
            "the loss in 4400th batch is: 19.043507\n",
            "the loss in 4600th batch is: 19.133930\n",
            "the loss in 4800th batch is: 18.651178\n",
            "the loss in 5000th batch is: 19.248825\n",
            "the loss in 5200th batch is: 19.213644\n",
            "the loss in 5400th batch is: 18.777094\n",
            "the loss in 5600th batch is: 18.980221\n",
            "epoch 5\n",
            "the loss in 5800th batch is: 19.014532\n",
            "the loss in 6000th batch is: 19.034681\n",
            "the loss in 6200th batch is: 18.822659\n",
            "the loss in 6400th batch is: 18.978277\n",
            "the loss in 6600th batch is: 18.646379\n",
            "the loss in 6800th batch is: 18.823242\n",
            "the loss in 7000th batch is: 18.830278\n",
            "the loss in 7200th batch is: 18.799038\n",
            "epoch 6\n",
            "the loss in 7400th batch is: 18.892332\n",
            "the loss in 7600th batch is: 18.624367\n",
            "the loss in 7800th batch is: 18.732817\n",
            "the loss in 8000th batch is: 18.292068\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5754.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.054689, 0.043509\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6829.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.064906, 0.046793\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7538.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.071644, 0.048574\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8146.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.077423, 0.049939\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 18.924652\n",
            "the loss in 8400th batch is: 18.355011\n",
            "the loss in 8600th batch is: 18.349632\n",
            "epoch 7\n",
            "the loss in 8800th batch is: 18.606697\n",
            "the loss in 9000th batch is: 18.389843\n",
            "the loss in 9200th batch is: 18.238005\n",
            "the loss in 9400th batch is: 18.318914\n",
            "the loss in 9600th batch is: 17.773102\n",
            "the loss in 9800th batch is: 17.850483\n",
            "the loss in 10000th batch is: 17.760397\n",
            "epoch 8\n",
            "the loss in 10200th batch is: 17.537590\n",
            "the loss in 10400th batch is: 17.771852\n",
            "the loss in 10600th batch is: 17.264114\n",
            "the loss in 10800th batch is: 17.254421\n",
            "the loss in 11000th batch is: 17.845951\n",
            "the loss in 11200th batch is: 17.330254\n",
            "the loss in 11400th batch is: 17.420116\n",
            "epoch 9\n",
            "the loss in 11600th batch is: 17.763882\n",
            "the loss in 11800th batch is: 17.978565\n",
            "the loss in 12000th batch is: 17.906822\n",
            "the loss in 12200th batch is: 17.660145\n",
            "the loss in 12400th batch is: 17.474293\n",
            "the loss in 12600th batch is: 17.847767\n",
            "the loss in 12800th batch is: 17.723660\n",
            "epoch 10\n",
            "the loss in 13000th batch is: 17.849329\n",
            "the loss in 13200th batch is: 17.902666\n",
            "the loss in 13400th batch is: 17.859425\n",
            "the loss in 13600th batch is: 17.529770\n",
            "the loss in 13800th batch is: 17.578959\n",
            "the loss in 14000th batch is: 17.528238\n",
            "the loss in 14200th batch is: 17.453720\n",
            "the loss in 14400th batch is: 16.982550\n",
            "epoch 11\n",
            "the loss in 14600th batch is: 17.395071\n",
            "the loss in 14800th batch is: 17.082268\n",
            "the loss in 15000th batch is: 17.221951\n",
            "the loss in 15200th batch is: 4.947017\n",
            "the loss in 15400th batch is: 4.885324\n",
            "the loss in 15600th batch is: 4.762140\n",
            "the loss in 15800th batch is: 4.704180\n",
            "epoch 12\n",
            "the loss in 16000th batch is: 4.658453\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6761.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.064260, 0.050011\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8010.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.076131, 0.053847\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8816.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.083791, 0.055875\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9442.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.089741, 0.057280\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 4.714757\n",
            "the loss in 16400th batch is: 4.427466\n",
            "the loss in 16600th batch is: 4.557017\n",
            "the loss in 16800th batch is: 4.584215\n",
            "the loss in 17000th batch is: 4.404205\n",
            "the loss in 17200th batch is: 4.534817\n",
            "epoch 13\n",
            "the loss in 17400th batch is: 4.663785\n",
            "the loss in 17600th batch is: 4.577183\n",
            "the loss in 17800th batch is: 4.443162\n",
            "the loss in 18000th batch is: 4.541711\n",
            "the loss in 18200th batch is: 4.558217\n",
            "the loss in 18400th batch is: 4.569410\n",
            "the loss in 18600th batch is: 4.381050\n",
            "epoch 14\n",
            "the loss in 18800th batch is: 4.092698\n",
            "the loss in 19000th batch is: 4.542518\n",
            "the loss in 19200th batch is: 4.697655\n",
            "the loss in 19400th batch is: 4.319181\n",
            "the loss in 19600th batch is: 4.333861\n",
            "the loss in 19800th batch is: 4.431494\n",
            "the loss in 20000th batch is: 4.306123\n",
            "epoch 15\n",
            "the loss in 20200th batch is: 4.473713\n",
            "the loss in 20400th batch is: 4.036120\n",
            "the loss in 20600th batch is: 4.154074\n",
            "the loss in 20800th batch is: 4.517953\n",
            "the loss in 21000th batch is: 4.184213\n",
            "the loss in 21200th batch is: 4.219911\n",
            "the loss in 21400th batch is: 4.302462\n",
            "the loss in 21600th batch is: 4.292623\n",
            "epoch 16\n",
            "the loss in 21800th batch is: 4.116622\n",
            "the loss in 22000th batch is: 4.368478\n",
            "the loss in 22200th batch is: 4.043501\n",
            "the loss in 22400th batch is: 4.278872\n",
            "the loss in 22600th batch is: 4.149632\n",
            "the loss in 22800th batch is: 4.312620\n",
            "the loss in 23000th batch is: 4.176546\n",
            "epoch 17\n",
            "the loss in 23200th batch is: 4.152311\n",
            "the loss in 23400th batch is: 3.749462\n",
            "the loss in 23600th batch is: 4.207377\n",
            "the loss in 23800th batch is: 4.011995\n",
            "the loss in 24000th batch is: 3.918668\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:105214\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6807.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.064697, 0.049415\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8148.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.077442, 0.053529\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8980.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.085350, 0.055620\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9564.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.090900, 0.056930\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 3.970670\n",
            "the loss in 24400th batch is: 4.043755\n",
            "epoch 18\n",
            "the loss in 24600th batch is: 3.815622\n",
            "the loss in 24800th batch is: 3.961305\n",
            "the loss in 25000th batch is: 4.080728\n",
            "the loss in 25200th batch is: 4.065499\n",
            "the loss in 25400th batch is: 3.907128\n",
            "the loss in 25600th batch is: 4.038206\n",
            "the loss in 25800th batch is: 3.912242\n",
            "epoch 19\n",
            "the loss in 26000th batch is: 4.230778\n",
            "the loss in 26200th batch is: 3.811012\n",
            "the loss in 26400th batch is: 3.694996\n",
            "the loss in 26600th batch is: 4.106956\n",
            "the loss in 26800th batch is: 3.899830\n",
            "the loss in 27000th batch is: 3.930719\n",
            "the loss in 27200th batch is: 3.777328\n",
            "epoch 20\n",
            "the loss in 27400th batch is: 3.429886\n",
            "the loss in 27600th batch is: 3.693101\n",
            "the loss in 27800th batch is: 3.706505\n",
            "the loss in 28000th batch is: 3.959571\n",
            "the loss in 28200th batch is: 3.673733\n",
            "the loss in 28400th batch is: 3.443774\n",
            "the loss in 28600th batch is: 3.651904\n",
            "the loss in 28800th batch is: 3.817008\n",
            "Training completed...\n",
            "Evaluating test dataset...\n",
            "\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:53316\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3312.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.062120, 0.046219\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 4044.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.075850, 0.050656\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4510.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.084590, 0.052970\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4850.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.090967, 0.054476\n",
            "#############################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCgn1K4Pmc5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szheng3/recommendation-system/blob/main/Explore_CQL/DLR2/HM_CQL_SA2C_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# SA2C-SASRec Recommender on H&M Data with Conservative Q-learning\n",
        "\n",
        "In this notebook we train an SA2C_SASrec model without and with CQL to train for recommendation on H&M dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgK2r88Mmkd",
        "outputId": "1509b1e0-2e4f-417b-ddb9-119debb210f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'recommendation-system'...\n",
            "remote: Enumerating objects: 1622, done.\u001b[K\n",
            "remote: Counting objects: 100% (403/403), done.\u001b[K\n",
            "remote: Compressing objects: 100% (216/216), done.\u001b[K\n",
            "remote: Total 1622 (delta 226), reused 331 (delta 186), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1622/1622), 11.71 MiB | 9.93 MiB/s, done.\n",
            "Resolving deltas: 100% (856/856), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the git repository\n",
        "!git clone https://github.com/szheng3/recommendation-system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3pkxR1AsDW",
        "outputId": "2eb28aaf-0446-493b-882c-13ff30099d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting d3rlpy\n",
            "  Downloading d3rlpy-1.1.1.tar.gz (317 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.6/317.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (1.2.2)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (4.65.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (3.8.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (0.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (8.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (4.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from d3rlpy) (1.10.1)\n",
            "Collecting structlog\n",
            "  Downloading structlog-23.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->d3rlpy) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->d3rlpy) (2.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->d3rlpy) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->d3rlpy) (1.2.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->d3rlpy) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->d3rlpy) (23.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->d3rlpy) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->d3rlpy) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->d3rlpy) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->d3rlpy) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->d3rlpy) (1.3.0)\n",
            "Building wheels for collected packages: d3rlpy\n",
            "  Building wheel for d3rlpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for d3rlpy: filename=d3rlpy-1.1.1-cp310-cp310-linux_x86_64.whl size=1257776 sha256=54852be99a426baac3ae8bd79c6767e7cd7c28089d96301f8a9d9c8c3413fc6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/c4/aab790777bd0d1358b9e8cc391621a4e0e2b10e7cd03406ad6\n",
            "Successfully built d3rlpy\n",
            "Installing collected packages: trfl, tensorboardX, structlog, colorama, d3rlpy\n",
            "Successfully installed colorama-0.4.6 d3rlpy-1.1.1 structlog-23.1.0 tensorboardX-2.6 trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# installing missing libraries (specifically for google colab)\n",
        "!pip install trfl d3rlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the H&M Dataset transaction log file from AWS S3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7SMHfSMiHI",
        "outputId": "30a2bd56-a792-4454-e1b5-142e7ccef578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-03 16:29:52--  https://aipi590.s3.amazonaws.com/transactions_train.csv\n",
            "Resolving aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)... 52.216.237.43, 52.217.47.52, 3.5.3.139, ...\n",
            "Connecting to aipi590.s3.amazonaws.com (aipi590.s3.amazonaws.com)|52.216.237.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3488002253 (3.2G) [text/csv]\n",
            "Saving to: ‘/content/recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’\n",
            "\n",
            "transactions_train. 100%[===================>]   3.25G  12.7MB/s    in 4m 30s  \n",
            "\n",
            "2023-05-03 16:34:23 (12.3 MB/s) - ‘/content/recommendation-system/Explore_CQL/Data/HM_data/transactions_train.csv’ saved [3488002253/3488002253]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# downloading the \"transactions_train.csv\" datafile from the H&M Dataset\n",
        "!wget https://aipi590.s3.amazonaws.com/transactions_train.csv -P \"/content/recommendation-system/Explore_CQL/Data/HM_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Run the \"gen_replay_buffer.py\" script to pre-process data and generate replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-MWI_XktTHX",
        "outputId": "959d4947-41bf-40ee-d06f-bc176518708b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start reading all transaction data ...\n",
            "Finish reading in 00:00:26\n",
            "\n",
            "Filter and save all valid sampled data\n",
            "/content/recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer_HM.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sampled_sessions['valid_session'] = sampled_sessions.session_id.map(sampled_sessions.groupby('session_id')['item_id'].size() > 2)\n",
            "Index(['timestamp', 'session_id', 'item_id', 'price', 'sales_channel_id'], dtype='object')\n",
            "\n",
            "Start counting popularity ...\n",
            "1049917it [00:35, 29293.42it/s]\n",
            "Popularity finished in 00:00:35\n",
            "\n",
            "Start spliting into train, val, test data ...\n",
            "\n",
            "           Generate Replay Buffer:\n",
            "                Total Session Size : 100000\n",
            "                     Train:      70000 ids | 737354 actions\n",
            "                     Validation: 20000 ids | 208638 actions\n",
            "                     Test:       10000 ids | 103925 actions\n",
            "                     \n",
            "                Random : True\n",
            "                Random Seed : 1234\n",
            "                Format : paper\n",
            "    \n",
            "                Total session id number : 1245612\n",
            "                Total item id number  : 96222\n",
            "    \n",
            "Generating training replay buffer\n",
            "100% 49019/49019 [00:43<00:00, 1115.28it/s]\n"
          ]
        }
      ],
      "source": [
        "# Executing the python script \"gen_replay_buffer\" to sample the given H&M dataset\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/gen_replay_buffer_HM.py\" --size=100000 --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SASRec-SNQN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "fc85e711-4d6d-4fce-84db-15f20a7362cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 22:42:04.817340: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 22:42:05.804693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not using CQL loss\n",
            "2023-05-03 22:42:07.696720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 22:42:07.729779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:07.761689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:07.761959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:07.920882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 22:42:07.979939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-03 22:42:08.021943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "Not using CQL loss\n",
            "2023-05-03 22:42:10.811700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 22:42:10.961856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 22:42:11.019216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 22:42:11.061119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-03 22:42:16.450281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:16.450598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:16.450781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:17.330409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:17.330722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:17.330906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:42:17.331041: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 22:42:17.331079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 22:42:17.418216: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "epoch 1\n",
            "2023-05-03 22:42:19.495711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 12.100731\n",
            "the loss in 400th batch is: 11.051951\n",
            "the loss in 600th batch is: 10.942413\n",
            "the loss in 800th batch is: 10.818802\n",
            "the loss in 1000th batch is: 11.033083\n",
            "the loss in 1200th batch is: 10.757754\n",
            "the loss in 1400th batch is: 10.894309\n",
            "the loss in 1600th batch is: 10.706808\n",
            "the loss in 1800th batch is: 10.607731\n",
            "the loss in 2000th batch is: 10.775235\n",
            "the loss in 2200th batch is: 10.501701\n",
            "the loss in 2400th batch is: 10.629546\n",
            "the loss in 2600th batch is: 10.371352\n",
            "the loss in 2800th batch is: 10.342762\n",
            "epoch 2\n",
            "the loss in 3000th batch is: 10.221030\n",
            "the loss in 3200th batch is: 10.324409\n",
            "the loss in 3400th batch is: 10.306085\n",
            "the loss in 3600th batch is: 10.396588\n",
            "the loss in 3800th batch is: 10.275434\n",
            "the loss in 4000th batch is: 10.167109\n",
            "the loss in 4200th batch is: 10.182146\n",
            "the loss in 4400th batch is: 10.381620\n",
            "the loss in 4600th batch is: 9.977527\n",
            "the loss in 4800th batch is: 10.313948\n",
            "the loss in 5000th batch is: 10.239130\n",
            "the loss in 5200th batch is: 9.947042\n",
            "the loss in 5400th batch is: 9.939034\n",
            "the loss in 5600th batch is: 9.965425\n",
            "epoch 3\n",
            "the loss in 5800th batch is: 9.810809\n",
            "the loss in 6000th batch is: 9.720061\n",
            "the loss in 6200th batch is: 10.033210\n",
            "the loss in 6400th batch is: 9.799089\n",
            "the loss in 6600th batch is: 9.732585\n",
            "the loss in 6800th batch is: 9.727661\n",
            "the loss in 7000th batch is: 9.939846\n",
            "the loss in 7200th batch is: 9.651072\n",
            "the loss in 7400th batch is: 9.544275\n",
            "the loss in 7600th batch is: 9.652045\n",
            "the loss in 7800th batch is: 9.413359\n",
            "the loss in 8000th batch is: 9.800640\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 11528.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.055254, 0.043876\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 14030.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.067246, 0.047741\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 15737.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.075427, 0.049905\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 17073.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.081831, 0.051417\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 9.591596\n",
            "the loss in 8400th batch is: 9.556165\n",
            "the loss in 8600th batch is: 9.553814\n",
            "epoch 4\n",
            "the loss in 8800th batch is: 9.545129\n",
            "the loss in 9000th batch is: 9.478119\n",
            "the loss in 9200th batch is: 9.823928\n",
            "the loss in 9400th batch is: 9.057016\n",
            "the loss in 9600th batch is: 9.430508\n",
            "the loss in 9800th batch is: 9.633316\n",
            "the loss in 10000th batch is: 9.087912\n",
            "the loss in 10200th batch is: 9.299664\n",
            "the loss in 10400th batch is: 9.451952\n",
            "the loss in 10600th batch is: 9.199318\n",
            "the loss in 10800th batch is: 9.078647\n",
            "the loss in 11000th batch is: 9.491251\n",
            "the loss in 11200th batch is: 9.331200\n",
            "the loss in 11400th batch is: 9.335944\n",
            "epoch 5\n",
            "the loss in 11600th batch is: 8.790311\n",
            "the loss in 11800th batch is: 9.356157\n",
            "the loss in 12000th batch is: 8.807373\n",
            "the loss in 12200th batch is: 9.272241\n",
            "the loss in 12400th batch is: 9.181086\n",
            "the loss in 12600th batch is: 8.881977\n",
            "the loss in 12800th batch is: 9.087452\n",
            "the loss in 13000th batch is: 9.064682\n",
            "the loss in 13200th batch is: 8.799263\n",
            "the loss in 13400th batch is: 8.690549\n",
            "the loss in 13600th batch is: 8.992306\n",
            "the loss in 13800th batch is: 8.514112\n",
            "the loss in 14000th batch is: 9.045154\n",
            "the loss in 14200th batch is: 8.610711\n",
            "the loss in 14400th batch is: 8.646693\n",
            "epoch 6\n",
            "the loss in 14600th batch is: 9.098922\n",
            "the loss in 14800th batch is: 9.154854\n",
            "the loss in 15000th batch is: 8.737975\n",
            "the loss in 15200th batch is: 5.178876\n",
            "the loss in 15400th batch is: 4.595160\n",
            "the loss in 15600th batch is: 4.719183\n",
            "the loss in 15800th batch is: 4.772879\n",
            "the loss in 16000th batch is: 4.634844\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 16030.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.076832, 0.061347\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 18932.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.090741, 0.065842\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 20832.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.099848, 0.068251\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 22366.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.107200, 0.069986\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 4.799874\n",
            "the loss in 16400th batch is: 4.465031\n",
            "the loss in 16600th batch is: 4.818475\n",
            "the loss in 16800th batch is: 4.722496\n",
            "the loss in 17000th batch is: 4.906477\n",
            "the loss in 17200th batch is: 4.816836\n",
            "epoch 7\n",
            "the loss in 17400th batch is: 4.738023\n",
            "the loss in 17600th batch is: 5.041323\n",
            "the loss in 17800th batch is: 4.797279\n",
            "the loss in 18000th batch is: 4.924280\n",
            "the loss in 18200th batch is: 4.751800\n",
            "the loss in 18400th batch is: 4.601888\n",
            "the loss in 18600th batch is: 4.807987\n",
            "the loss in 18800th batch is: 4.883700\n",
            "the loss in 19000th batch is: 4.817020\n",
            "the loss in 19200th batch is: 4.789238\n",
            "the loss in 19400th batch is: 4.876228\n",
            "the loss in 19600th batch is: 4.944418\n",
            "the loss in 19800th batch is: 4.869339\n",
            "the loss in 20000th batch is: 4.584318\n",
            "epoch 8\n",
            "the loss in 20200th batch is: 4.908217\n",
            "the loss in 20400th batch is: 4.922997\n",
            "the loss in 20600th batch is: 4.944599\n",
            "the loss in 20800th batch is: 4.820577\n",
            "the loss in 21000th batch is: 4.889247\n",
            "the loss in 21200th batch is: 4.685244\n",
            "the loss in 21400th batch is: 4.557967\n",
            "the loss in 21600th batch is: 4.638570\n",
            "the loss in 21800th batch is: 4.411957\n",
            "the loss in 22000th batch is: 4.864450\n",
            "the loss in 22200th batch is: 4.774079\n",
            "the loss in 22400th batch is: 4.559797\n",
            "the loss in 22600th batch is: 4.374320\n",
            "the loss in 22800th batch is: 4.776494\n",
            "the loss in 23000th batch is: 4.540007\n",
            "epoch 9\n",
            "the loss in 23200th batch is: 4.684614\n",
            "the loss in 23400th batch is: 4.464447\n",
            "the loss in 23600th batch is: 4.809963\n",
            "the loss in 23800th batch is: 4.570107\n",
            "the loss in 24000th batch is: 4.451144\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17618.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.084443, 0.067993\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20657.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.099009, 0.072702\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22594.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.108293, 0.075156\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24089.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.115458, 0.076848\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 4.700435\n",
            "the loss in 24400th batch is: 4.625635\n",
            "the loss in 24600th batch is: 4.384437\n",
            "the loss in 24800th batch is: 4.983187\n",
            "the loss in 25000th batch is: 4.499565\n",
            "the loss in 25200th batch is: 4.622146\n",
            "the loss in 25400th batch is: 4.602665\n",
            "the loss in 25600th batch is: 4.440525\n",
            "the loss in 25800th batch is: 4.658845\n",
            "epoch 10\n",
            "the loss in 26000th batch is: 4.642914\n",
            "the loss in 26200th batch is: 4.584785\n",
            "the loss in 26400th batch is: 4.755443\n",
            "the loss in 26600th batch is: 4.526470\n",
            "the loss in 26800th batch is: 4.621582\n",
            "the loss in 27000th batch is: 4.457760\n",
            "the loss in 27200th batch is: 4.213496\n",
            "the loss in 27400th batch is: 4.809710\n",
            "the loss in 27600th batch is: 4.879869\n",
            "the loss in 27800th batch is: 4.610961\n",
            "the loss in 28000th batch is: 4.349525\n",
            "the loss in 28200th batch is: 4.477087\n",
            "the loss in 28400th batch is: 4.731009\n",
            "the loss in 28600th batch is: 4.499691\n",
            "the loss in 28800th batch is: 4.508158\n",
            "epoch 11\n",
            "the loss in 29000th batch is: 4.441582\n",
            "the loss in 29200th batch is: 4.728088\n",
            "the loss in 29400th batch is: 4.451115\n",
            "the loss in 29600th batch is: 4.726501\n",
            "the loss in 29800th batch is: 4.314409\n",
            "the loss in 30000th batch is: 4.333168\n",
            "the loss in 30200th batch is: 4.614874\n",
            "the loss in 30400th batch is: 4.495535\n",
            "the loss in 30600th batch is: 4.582780\n",
            "the loss in 30800th batch is: 4.540118\n",
            "the loss in 31000th batch is: 4.485058\n",
            "the loss in 31200th batch is: 4.248716\n",
            "the loss in 31400th batch is: 4.549934\n",
            "the loss in 31600th batch is: 4.424884\n",
            "epoch 12\n",
            "the loss in 31800th batch is: 4.616323\n",
            "the loss in 32000th batch is: 4.458659\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 18371.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.088052, 0.070624\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 21422.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.102675, 0.075359\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 23331.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.111825, 0.077780\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24819.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.118957, 0.079464\n",
            "#############################################################\n",
            "the loss in 32200th batch is: 4.746277\n",
            "the loss in 32400th batch is: 4.368467\n",
            "the loss in 32600th batch is: 4.558133\n",
            "the loss in 32800th batch is: 4.495490\n",
            "the loss in 33000th batch is: 4.393119\n",
            "the loss in 33200th batch is: 4.460047\n",
            "the loss in 33400th batch is: 4.371718\n",
            "the loss in 33600th batch is: 4.446266\n",
            "the loss in 33800th batch is: 4.092575\n",
            "the loss in 34000th batch is: 4.302051\n",
            "the loss in 34200th batch is: 4.243698\n",
            "the loss in 34400th batch is: 4.231685\n",
            "epoch 13\n",
            "the loss in 34600th batch is: 4.249631\n",
            "the loss in 34800th batch is: 4.285559\n",
            "the loss in 35000th batch is: 4.228946\n",
            "the loss in 35200th batch is: 4.099757\n",
            "the loss in 35400th batch is: 4.389443\n",
            "the loss in 35600th batch is: 4.057989\n",
            "the loss in 35800th batch is: 4.714091\n",
            "the loss in 36000th batch is: 4.094066\n",
            "the loss in 36200th batch is: 4.161233\n",
            "the loss in 36400th batch is: 4.189759\n",
            "the loss in 36600th batch is: 4.149515\n",
            "the loss in 36800th batch is: 4.029951\n",
            "the loss in 37000th batch is: 4.075653\n",
            "the loss in 37200th batch is: 4.229231\n",
            "the loss in 37400th batch is: 4.179284\n",
            "epoch 14\n",
            "the loss in 37600th batch is: 4.077943\n",
            "the loss in 37800th batch is: 4.253057\n",
            "the loss in 38000th batch is: 4.235743\n",
            "the loss in 38200th batch is: 4.197285\n",
            "the loss in 38400th batch is: 3.954462\n",
            "the loss in 38600th batch is: 4.106992\n",
            "the loss in 38800th batch is: 4.177587\n",
            "the loss in 39000th batch is: 4.382261\n",
            "the loss in 39200th batch is: 4.429625\n",
            "the loss in 39400th batch is: 4.186124\n",
            "the loss in 39600th batch is: 4.000113\n",
            "the loss in 39800th batch is: 3.933774\n",
            "the loss in 40000th batch is: 4.318516\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 18271.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.087573, 0.069374\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 21426.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.102695, 0.074265\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 23420.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.112252, 0.076792\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24873.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.119216, 0.078435\n",
            "#############################################################\n",
            "the loss in 40200th batch is: 4.008559\n",
            "epoch 15\n",
            "the loss in 40400th batch is: 3.912244\n",
            "the loss in 40600th batch is: 4.096495\n",
            "the loss in 40800th batch is: 3.797821\n",
            "the loss in 41000th batch is: 4.165778\n",
            "the loss in 41200th batch is: 4.169497\n",
            "the loss in 41400th batch is: 4.148554\n",
            "the loss in 41600th batch is: 4.248254\n",
            "the loss in 41800th batch is: 4.141351\n",
            "the loss in 42000th batch is: 3.846869\n",
            "the loss in 42200th batch is: 4.029755\n",
            "the loss in 42400th batch is: 3.906269\n",
            "the loss in 42600th batch is: 4.102282\n",
            "the loss in 42800th batch is: 4.128672\n",
            "the loss in 43000th batch is: 3.880004\n",
            "the loss in 43200th batch is: 4.004483\n",
            "epoch 16\n",
            "the loss in 43400th batch is: 3.931063\n",
            "the loss in 43600th batch is: 4.175063\n",
            "the loss in 43800th batch is: 4.016230\n",
            "the loss in 44000th batch is: 3.940131\n",
            "the loss in 44200th batch is: 3.920979\n",
            "the loss in 44400th batch is: 4.153616\n",
            "the loss in 44600th batch is: 3.813005\n",
            "the loss in 44800th batch is: 3.959659\n",
            "the loss in 45000th batch is: 3.983345\n",
            "the loss in 45200th batch is: 3.980638\n",
            "the loss in 45400th batch is: 3.689883\n",
            "the loss in 45600th batch is: 3.841059\n",
            "the loss in 45800th batch is: 4.256598\n",
            "the loss in 46000th batch is: 3.928681\n",
            "epoch 17\n",
            "the loss in 46200th batch is: 4.303191\n",
            "the loss in 46400th batch is: 4.082307\n",
            "the loss in 46600th batch is: 3.977064\n",
            "the loss in 46800th batch is: 4.003533\n",
            "the loss in 47000th batch is: 3.880912\n",
            "the loss in 47200th batch is: 4.188329\n",
            "the loss in 47400th batch is: 3.979055\n",
            "the loss in 47600th batch is: 3.906026\n",
            "the loss in 47800th batch is: 3.667579\n",
            "the loss in 48000th batch is: 3.582080\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17825.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.085435, 0.066444\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 21107.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.101166, 0.071535\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 23124.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.110833, 0.074088\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24698.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.118377, 0.075869\n",
            "#############################################################\n",
            "the loss in 48200th batch is: 3.891668\n",
            "the loss in 48400th batch is: 4.150595\n",
            "the loss in 48600th batch is: 3.862833\n",
            "the loss in 48800th batch is: 3.901262\n",
            "epoch 18\n",
            "the loss in 49000th batch is: 3.972747\n",
            "the loss in 49200th batch is: 3.667511\n",
            "the loss in 49400th batch is: 3.738643\n",
            "the loss in 49600th batch is: 4.056190\n",
            "the loss in 49800th batch is: 3.945155\n",
            "the loss in 50000th batch is: 3.674823\n",
            "the loss in 50200th batch is: 3.706667\n",
            "the loss in 50400th batch is: 3.902579\n",
            "the loss in 50600th batch is: 3.847964\n",
            "the loss in 50800th batch is: 3.846664\n",
            "the loss in 51000th batch is: 3.934837\n",
            "the loss in 51200th batch is: 3.831049\n",
            "the loss in 51400th batch is: 3.689605\n",
            "the loss in 51600th batch is: 3.936600\n",
            "the loss in 51800th batch is: 3.889533\n",
            "epoch 19\n",
            "the loss in 52000th batch is: 3.774443\n",
            "the loss in 52200th batch is: 3.854235\n",
            "the loss in 52400th batch is: 3.779757\n",
            "the loss in 52600th batch is: 3.508007\n",
            "the loss in 52800th batch is: 3.525388\n",
            "the loss in 53000th batch is: 3.821266\n",
            "the loss in 53200th batch is: 3.999549\n",
            "the loss in 53400th batch is: 3.923079\n",
            "the loss in 53600th batch is: 3.827976\n",
            "the loss in 53800th batch is: 3.776128\n",
            "the loss in 54000th batch is: 3.665117\n",
            "the loss in 54200th batch is: 3.989027\n",
            "the loss in 54400th batch is: 3.797653\n",
            "the loss in 54600th batch is: 3.755372\n",
            "epoch 20\n",
            "the loss in 54800th batch is: 3.729383\n",
            "the loss in 55000th batch is: 3.593225\n",
            "the loss in 55200th batch is: 3.725780\n",
            "the loss in 55400th batch is: 3.497865\n",
            "the loss in 55600th batch is: 3.707267\n",
            "the loss in 55800th batch is: 3.651386\n",
            "the loss in 56000th batch is: 3.855069\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17274.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.082794, 0.063625\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20709.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.099258, 0.068954\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22723.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.108911, 0.071506\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24282.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.116383, 0.073272\n",
            "#############################################################\n",
            "the loss in 56200th batch is: 3.887772\n",
            "the loss in 56400th batch is: 3.780058\n",
            "the loss in 56600th batch is: 3.513774\n",
            "the loss in 56800th batch is: 3.949704\n",
            "the loss in 57000th batch is: 3.659811\n",
            "the loss in 57200th batch is: 3.836049\n",
            "the loss in 57400th batch is: 4.141275\n",
            "the loss in 57600th batch is: 3.656987\n",
            "Training completed...\n",
            "Evaluating test dataset...\n",
            "\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:103925\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8437.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.081184, 0.061901\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10191.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.098061, 0.067352\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11229.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.108049, 0.069990\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11992.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.115391, 0.071722\n",
            "#############################################################\n"
          ]
        }
      ],
      "source": [
        "# Executing the python script \"SA2C_v3.py\" to train a SA2C-SASrec model on the sampled data and evaluate it on validation data using HR (hit rate) and NDCG metrics for different values of k\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/SA2C_v3_5.py\" --model=SASRec --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data/\" --epoch=20"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vZxRqVldJUwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the python script \"SA2C_v3.py\" to train a SA2C-SASrec model on the sampled data with CQL and evaluate it on validation data using HR (hit rate) and NDCG metrics for different values of k\n",
        "!python \"/content/recommendation-system/Explore_CQL/DLR2/src/SA2C_v3_5.py\" --model=SASRec --CQL_alpha=1.0 --data=\"/content/recommendation-system/Explore_CQL/Data/HM_data/\" --epoch=20"
      ],
      "metadata": {
        "id": "M5NVOfakncxU",
        "outputId": "ed2045dc-84fb-480d-b87b-1ab3a9784b87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 05:30:34.409139: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 05:30:35.407704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using CQL loss.\n",
            "2023-05-04 05:30:37.244359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-04 05:30:37.276582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:37.309663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:37.309910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:37.458268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-04 05:30:37.511383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "2023-05-04 05:30:37.549737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype bool\n",
            "\t [[{{node Placeholder}}]]\n",
            "Using CQL loss.\n",
            "2023-05-04 05:30:40.524904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 05:30:40.680417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 05:30:40.739337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 05:30:40.782590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype bool\n",
            "\t [[{{node Placeholder_1}}]]\n",
            "2023-05-04 05:30:46.320082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:46.320385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:46.320564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:47.199039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:47.199281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:47.199484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-04 05:30:47.199641: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-04 05:30:47.199686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-04 05:30:47.289354: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "epoch 1\n",
            "2023-05-04 05:30:49.309050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "the loss in 200th batch is: 37.076870\n",
            "the loss in 400th batch is: 34.574894\n",
            "the loss in 600th batch is: 32.791389\n",
            "the loss in 800th batch is: 31.133625\n",
            "the loss in 1000th batch is: 30.942619\n",
            "the loss in 1200th batch is: 29.584925\n",
            "the loss in 1400th batch is: 28.710260\n",
            "the loss in 1600th batch is: 27.930870\n",
            "the loss in 1800th batch is: 28.978371\n",
            "the loss in 2000th batch is: 28.710505\n",
            "the loss in 2200th batch is: 29.018337\n",
            "the loss in 2400th batch is: 28.520554\n",
            "the loss in 2600th batch is: 28.454279\n",
            "the loss in 2800th batch is: 28.512583\n",
            "epoch 2\n",
            "the loss in 3000th batch is: 28.563229\n",
            "the loss in 3200th batch is: 28.608189\n",
            "the loss in 3400th batch is: 28.680227\n",
            "the loss in 3600th batch is: 28.837040\n",
            "the loss in 3800th batch is: 28.929541\n",
            "the loss in 4000th batch is: 28.777561\n",
            "the loss in 4200th batch is: 28.806305\n",
            "the loss in 4400th batch is: 28.793951\n",
            "the loss in 4600th batch is: 28.397110\n",
            "the loss in 4800th batch is: 28.938324\n",
            "the loss in 5000th batch is: 29.077360\n",
            "the loss in 5200th batch is: 28.726954\n",
            "the loss in 5400th batch is: 28.429413\n",
            "the loss in 5600th batch is: 28.954178\n",
            "epoch 3\n",
            "the loss in 5800th batch is: 28.517262\n",
            "the loss in 6000th batch is: 29.445997\n",
            "the loss in 6200th batch is: 29.018604\n",
            "the loss in 6400th batch is: 28.568111\n",
            "the loss in 6600th batch is: 28.779346\n",
            "the loss in 6800th batch is: 28.689770\n",
            "the loss in 7000th batch is: 28.604805\n",
            "the loss in 7200th batch is: 28.340469\n",
            "the loss in 7400th batch is: 28.629351\n",
            "the loss in 7600th batch is: 28.800549\n",
            "the loss in 7800th batch is: 28.666092\n",
            "the loss in 8000th batch is: 28.261780\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 9869.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.047302, 0.036742\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 12363.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.059256, 0.040603\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 14090.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.067533, 0.042790\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 15480.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.074195, 0.044365\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 28.850479\n",
            "the loss in 8400th batch is: 28.307146\n",
            "the loss in 8600th batch is: 28.273016\n",
            "epoch 4\n",
            "the loss in 8800th batch is: 28.831812\n",
            "the loss in 9000th batch is: 28.570024\n",
            "the loss in 9200th batch is: 29.249643\n",
            "the loss in 9400th batch is: 28.844440\n",
            "the loss in 9600th batch is: 28.344812\n",
            "the loss in 9800th batch is: 28.165806\n",
            "the loss in 10000th batch is: 28.345186\n",
            "the loss in 10200th batch is: 28.403713\n",
            "the loss in 10400th batch is: 28.185076\n",
            "the loss in 10600th batch is: 28.404713\n",
            "the loss in 10800th batch is: 28.287359\n",
            "the loss in 11000th batch is: 28.270132\n",
            "the loss in 11200th batch is: 27.871983\n",
            "the loss in 11400th batch is: 28.170366\n",
            "epoch 5\n",
            "the loss in 11600th batch is: 28.366589\n",
            "the loss in 11800th batch is: 28.181053\n",
            "the loss in 12000th batch is: 28.151289\n",
            "the loss in 12200th batch is: 28.249580\n",
            "the loss in 12400th batch is: 28.374699\n",
            "the loss in 12600th batch is: 28.458267\n",
            "the loss in 12800th batch is: 28.096371\n",
            "the loss in 13000th batch is: 27.340279\n",
            "the loss in 13200th batch is: 27.787766\n",
            "the loss in 13400th batch is: 28.063858\n",
            "the loss in 13600th batch is: 27.941589\n",
            "the loss in 13800th batch is: 27.760010\n",
            "the loss in 14000th batch is: 28.243389\n",
            "the loss in 14200th batch is: 28.247406\n",
            "the loss in 14400th batch is: 28.276709\n",
            "epoch 6\n",
            "the loss in 14600th batch is: 27.880451\n",
            "the loss in 14800th batch is: 28.695665\n",
            "the loss in 15000th batch is: 27.899267\n",
            "the loss in 15200th batch is: 5.635594\n",
            "the loss in 15400th batch is: 5.540426\n",
            "the loss in 15600th batch is: 5.461598\n",
            "the loss in 15800th batch is: 5.410952\n",
            "the loss in 16000th batch is: 5.125167\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 15249.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.073088, 0.057850\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 18161.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.087046, 0.062354\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 20144.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.096550, 0.064871\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 21801.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.104492, 0.066744\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.095463\n",
            "the loss in 16400th batch is: 5.145017\n",
            "the loss in 16600th batch is: 5.097873\n",
            "the loss in 16800th batch is: 4.872365\n",
            "the loss in 17000th batch is: 5.111227\n",
            "the loss in 17200th batch is: 5.264166\n",
            "epoch 7\n",
            "the loss in 17400th batch is: 4.959701\n",
            "the loss in 17600th batch is: 5.135674\n",
            "the loss in 17800th batch is: 5.055193\n",
            "the loss in 18000th batch is: 5.104817\n",
            "the loss in 18200th batch is: 4.962039\n",
            "the loss in 18400th batch is: 5.051432\n",
            "the loss in 18600th batch is: 4.977948\n",
            "the loss in 18800th batch is: 4.971797\n",
            "the loss in 19000th batch is: 4.945570\n",
            "the loss in 19200th batch is: 5.205448\n",
            "the loss in 19400th batch is: 4.793105\n",
            "the loss in 19600th batch is: 4.887369\n",
            "the loss in 19800th batch is: 5.072846\n",
            "the loss in 20000th batch is: 4.870162\n",
            "epoch 8\n",
            "the loss in 20200th batch is: 4.798882\n",
            "the loss in 20400th batch is: 4.787334\n",
            "the loss in 20600th batch is: 4.880449\n",
            "the loss in 20800th batch is: 5.025339\n",
            "the loss in 21000th batch is: 4.877533\n",
            "the loss in 21200th batch is: 4.770612\n",
            "the loss in 21400th batch is: 5.092427\n",
            "the loss in 21600th batch is: 4.888870\n",
            "the loss in 21800th batch is: 4.911474\n",
            "the loss in 22000th batch is: 4.729179\n",
            "the loss in 22200th batch is: 4.745569\n",
            "the loss in 22400th batch is: 4.848389\n",
            "the loss in 22600th batch is: 5.206766\n",
            "the loss in 22800th batch is: 4.656224\n",
            "the loss in 23000th batch is: 4.717988\n",
            "epoch 9\n",
            "the loss in 23200th batch is: 4.917751\n",
            "the loss in 23400th batch is: 4.716863\n",
            "the loss in 23600th batch is: 4.516696\n",
            "the loss in 23800th batch is: 4.641680\n",
            "the loss in 24000th batch is: 4.832509\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17283.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.082837, 0.066022\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20396.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.097758, 0.070838\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22372.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.107229, 0.073344\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 23941.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.114749, 0.075117\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 4.638690\n",
            "the loss in 24400th batch is: 4.616815\n",
            "the loss in 24600th batch is: 4.750234\n",
            "the loss in 24800th batch is: 4.577680\n",
            "the loss in 25000th batch is: 4.642367\n",
            "the loss in 25200th batch is: 4.703058\n",
            "the loss in 25400th batch is: 4.724688\n",
            "the loss in 25600th batch is: 4.475605\n",
            "the loss in 25800th batch is: 4.835814\n",
            "epoch 10\n",
            "the loss in 26000th batch is: 4.529866\n",
            "the loss in 26200th batch is: 4.547190\n",
            "the loss in 26400th batch is: 4.566272\n",
            "the loss in 26600th batch is: 4.597830\n",
            "the loss in 26800th batch is: 4.693489\n",
            "the loss in 27000th batch is: 4.577625\n",
            "the loss in 27200th batch is: 4.574456\n",
            "the loss in 27400th batch is: 4.401169\n",
            "the loss in 27600th batch is: 4.599541\n",
            "the loss in 27800th batch is: 4.442680\n",
            "the loss in 28000th batch is: 4.308043\n",
            "the loss in 28200th batch is: 4.214670\n",
            "the loss in 28400th batch is: 4.370056\n",
            "the loss in 28600th batch is: 4.644199\n",
            "the loss in 28800th batch is: 4.719627\n",
            "epoch 11\n",
            "the loss in 29000th batch is: 4.349774\n",
            "the loss in 29200th batch is: 4.700431\n",
            "the loss in 29400th batch is: 4.757513\n",
            "the loss in 29600th batch is: 4.508741\n",
            "the loss in 29800th batch is: 4.406330\n",
            "the loss in 30000th batch is: 4.432827\n",
            "the loss in 30200th batch is: 4.327002\n",
            "the loss in 30400th batch is: 4.630332\n",
            "the loss in 30600th batch is: 4.582534\n",
            "the loss in 30800th batch is: 4.400588\n",
            "the loss in 31000th batch is: 4.188195\n",
            "the loss in 31200th batch is: 4.462667\n",
            "the loss in 31400th batch is: 4.306559\n",
            "the loss in 31600th batch is: 4.370857\n",
            "epoch 12\n",
            "the loss in 31800th batch is: 4.224321\n",
            "the loss in 32000th batch is: 4.472596\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17815.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.085387, 0.067593\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20986.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.100586, 0.072506\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22954.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.110018, 0.074999\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24487.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.117366, 0.076735\n",
            "#############################################################\n",
            "the loss in 32200th batch is: 4.272470\n",
            "the loss in 32400th batch is: 4.628880\n",
            "the loss in 32600th batch is: 4.591432\n",
            "the loss in 32800th batch is: 4.380670\n",
            "the loss in 33000th batch is: 4.333393\n",
            "the loss in 33200th batch is: 4.119692\n",
            "the loss in 33400th batch is: 4.299281\n",
            "the loss in 33600th batch is: 4.272003\n",
            "the loss in 33800th batch is: 4.300504\n",
            "the loss in 34000th batch is: 4.491252\n",
            "the loss in 34200th batch is: 4.473513\n",
            "the loss in 34400th batch is: 4.292635\n",
            "epoch 13\n",
            "the loss in 34600th batch is: 4.298674\n",
            "the loss in 34800th batch is: 4.288381\n",
            "the loss in 35000th batch is: 4.284068\n",
            "the loss in 35200th batch is: 4.178774\n",
            "the loss in 35400th batch is: 4.248916\n",
            "the loss in 35600th batch is: 4.245543\n",
            "the loss in 35800th batch is: 3.979971\n",
            "the loss in 36000th batch is: 4.327127\n",
            "the loss in 36200th batch is: 4.346130\n",
            "the loss in 36400th batch is: 4.253793\n",
            "the loss in 36600th batch is: 3.863439\n",
            "the loss in 36800th batch is: 4.091153\n",
            "the loss in 37000th batch is: 4.259036\n",
            "the loss in 37200th batch is: 4.320099\n",
            "the loss in 37400th batch is: 4.089055\n",
            "epoch 14\n",
            "the loss in 37600th batch is: 4.592139\n",
            "the loss in 37800th batch is: 3.960103\n",
            "the loss in 38000th batch is: 4.130597\n",
            "the loss in 38200th batch is: 4.460280\n",
            "the loss in 38400th batch is: 4.150916\n",
            "the loss in 38600th batch is: 4.110189\n",
            "the loss in 38800th batch is: 4.191714\n",
            "the loss in 39000th batch is: 3.942127\n",
            "the loss in 39200th batch is: 4.243193\n",
            "the loss in 39400th batch is: 4.201047\n",
            "the loss in 39600th batch is: 4.309191\n",
            "the loss in 39800th batch is: 3.985781\n",
            "the loss in 40000th batch is: 4.204310\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17547.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.084103, 0.065644\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20870.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.100030, 0.070789\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22864.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.109587, 0.073320\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24399.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.116944, 0.075059\n",
            "#############################################################\n",
            "the loss in 40200th batch is: 4.284841\n",
            "epoch 15\n",
            "the loss in 40400th batch is: 4.153072\n",
            "the loss in 40600th batch is: 4.298529\n",
            "the loss in 40800th batch is: 3.975503\n",
            "the loss in 41000th batch is: 4.075894\n",
            "the loss in 41200th batch is: 4.131893\n",
            "the loss in 41400th batch is: 4.102855\n",
            "the loss in 41600th batch is: 4.104033\n",
            "the loss in 41800th batch is: 4.031085\n",
            "the loss in 42000th batch is: 4.061346\n",
            "the loss in 42200th batch is: 4.201395\n",
            "the loss in 42400th batch is: 3.854861\n",
            "the loss in 42600th batch is: 3.877176\n",
            "the loss in 42800th batch is: 4.082635\n",
            "the loss in 43000th batch is: 4.091686\n",
            "the loss in 43200th batch is: 3.802493\n",
            "epoch 16\n",
            "the loss in 43400th batch is: 3.834010\n",
            "the loss in 43600th batch is: 4.151137\n",
            "the loss in 43800th batch is: 3.716368\n",
            "the loss in 44000th batch is: 4.032824\n",
            "the loss in 44200th batch is: 3.848531\n",
            "the loss in 44400th batch is: 3.820726\n",
            "the loss in 44600th batch is: 3.824710\n",
            "the loss in 44800th batch is: 3.999199\n",
            "the loss in 45000th batch is: 3.965791\n",
            "the loss in 45200th batch is: 3.781989\n",
            "the loss in 45400th batch is: 3.877512\n",
            "the loss in 45600th batch is: 3.775086\n",
            "the loss in 45800th batch is: 3.718709\n",
            "the loss in 46000th batch is: 3.841043\n",
            "epoch 17\n",
            "the loss in 46200th batch is: 3.733649\n",
            "the loss in 46400th batch is: 3.908930\n",
            "the loss in 46600th batch is: 3.831114\n",
            "the loss in 46800th batch is: 3.776061\n",
            "the loss in 47000th batch is: 3.955466\n",
            "the loss in 47200th batch is: 3.620824\n",
            "the loss in 47400th batch is: 4.127342\n",
            "the loss in 47600th batch is: 3.654628\n",
            "the loss in 47800th batch is: 3.677950\n",
            "the loss in 48000th batch is: 3.830030\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 16966.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.081318, 0.062680\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20346.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.097518, 0.067923\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 22365.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.107195, 0.070485\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 23973.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.114902, 0.072306\n",
            "#############################################################\n",
            "the loss in 48200th batch is: 3.636483\n",
            "the loss in 48400th batch is: 3.949710\n",
            "the loss in 48600th batch is: 3.827162\n",
            "the loss in 48800th batch is: 3.845780\n",
            "epoch 18\n",
            "the loss in 49000th batch is: 3.803005\n",
            "the loss in 49200th batch is: 3.761019\n",
            "the loss in 49400th batch is: 3.886446\n",
            "the loss in 49600th batch is: 3.700057\n",
            "the loss in 49800th batch is: 3.835659\n",
            "the loss in 50000th batch is: 3.747769\n",
            "the loss in 50200th batch is: 3.562970\n",
            "the loss in 50400th batch is: 3.915071\n",
            "the loss in 50600th batch is: 3.837687\n",
            "the loss in 50800th batch is: 3.561898\n",
            "the loss in 51000th batch is: 3.664628\n",
            "the loss in 51200th batch is: 3.669718\n",
            "the loss in 51400th batch is: 3.578340\n",
            "the loss in 51600th batch is: 3.723181\n",
            "the loss in 51800th batch is: 3.832255\n",
            "epoch 19\n",
            "the loss in 52000th batch is: 3.617029\n",
            "the loss in 52200th batch is: 3.586835\n",
            "the loss in 52400th batch is: 3.386778\n",
            "the loss in 52600th batch is: 3.668339\n",
            "the loss in 52800th batch is: 3.671310\n",
            "the loss in 53000th batch is: 3.761604\n",
            "the loss in 53200th batch is: 3.619409\n",
            "the loss in 53400th batch is: 3.682353\n",
            "the loss in 53600th batch is: 3.960885\n",
            "the loss in 53800th batch is: 3.540741\n",
            "the loss in 54000th batch is: 3.614602\n",
            "the loss in 54200th batch is: 3.818743\n",
            "the loss in 54400th batch is: 3.484524\n",
            "the loss in 54600th batch is: 3.737667\n",
            "epoch 20\n",
            "the loss in 54800th batch is: 3.418807\n",
            "the loss in 55000th batch is: 3.552523\n",
            "the loss in 55200th batch is: 3.398377\n",
            "the loss in 55400th batch is: 3.668029\n",
            "the loss in 55600th batch is: 3.565354\n",
            "the loss in 55800th batch is: 3.850025\n",
            "the loss in 56000th batch is: 3.516006\n",
            "\n",
            "Beginning evaluation...\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:208638\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 16227.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.077776, 0.058921\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 19693.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.094388, 0.064293\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 21802.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.104497, 0.066967\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 23374.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.112031, 0.068747\n",
            "#############################################################\n",
            "the loss in 56200th batch is: 3.651177\n",
            "the loss in 56400th batch is: 3.611977\n",
            "the loss in 56600th batch is: 3.648139\n",
            "the loss in 56800th batch is: 3.707926\n",
            "the loss in 57000th batch is: 3.607432\n",
            "the loss in 57200th batch is: 3.571365\n",
            "the loss in 57400th batch is: 3.702088\n",
            "the loss in 57600th batch is: 3.323758\n",
            "Training completed...\n",
            "Evaluating test dataset...\n",
            "\n",
            "#############################################################\n",
            "total clicks: 0, total purchase:103925\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8067.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.077623, 0.058603\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9729.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.093616, 0.063774\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10794.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.103863, 0.066488\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11631.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.111917, 0.068389\n",
            "#############################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCgn1K4Pmc5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
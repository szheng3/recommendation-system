{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# Add Feature Recommender on H&M Data\n",
        "\n",
        "In this notebook we train an SNQN model to recomend a ranked list of items to users in the dataset. We are using H&M's e-commerce data to train this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vgK2r88Mmkd"
      },
      "outputs": [],
      "source": [
        "# cloning the git repository\n",
        "!git clone https://github.com/szheng3/recommendation-system.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtzL7uKEDo_d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY3pkxR1AsDW"
      },
      "outputs": [],
      "source": [
        "# installing missing libraries (specifically for google colab)\n",
        "!pip install trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the H&M Dataset transaction log file from AWS S3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA7SMHfSMiHI"
      },
      "outputs": [],
      "source": [
        "# downloading the \"transactions_train.csv\" datafile from the H&M Dataset\n",
        "!wget https://aipi590.s3.amazonaws.com/transactions_train.csv -P \"/content/recommendation-system/ItemFeatures/HM/data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Run the \"gen_replay_buffer.py\" script to pre-process data and generate replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-MWI_XktTHX"
      },
      "outputs": [],
      "source": [
        "# Executing the python script \"gen_replay_buffer\" to sample the given H&M dataset\n",
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/gen_replay_buffer.py\" --size=20000 --format=paper --data=\"/content/recommendation-system/ItemFeatures/HM/data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SASRec-SNQN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUk2eLLkFX0g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_statis = pd.read_pickle(os.path.join('/content/recommendation-system/ItemFeatures/HM/data/replay_buffer.df'))  # read data statistics, includeing state_size and item_num\n",
        "data_statis.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "ae431049-5561-4e89-c938-88a9ead9758f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_statis.df\treplay_buffer.df      sampled_test.df\ttransactions_train.csv\n",
            "pop_dict.txt\tsampled_sessions.csv  sampled_train.df\n",
            "readme.md\tsampled_sessions.df   sampled_val.df\n",
            "2023-05-01 22:21:56.968018: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-01 22:21:58.082413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:135: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-01 22:22:00.468420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:00.920476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:00.920786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:147: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:148: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,activation=None)\n",
            "2023-05-01 22:22:04.223074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:04.223524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:04.223858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:06.632025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:06.632327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:06.632534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 22:22:06.632680: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-01 22:22:06.632742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-01 22:22:06.664851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 11.595530\n",
            "the loss in 400th batch is: 11.099799\n",
            "the loss in 600th batch is: 10.728308\n",
            "the loss in 800th batch is: 10.707838\n",
            "the loss in 1000th batch is: 10.377281\n",
            "the loss in 1200th batch is: 10.019183\n",
            "the loss in 1400th batch is: 9.774337\n",
            "the loss in 1600th batch is: 9.571925\n",
            "the loss in 1800th batch is: 9.511646\n",
            "the loss in 2000th batch is: 9.556958\n",
            "the loss in 2200th batch is: 9.487170\n",
            "the loss in 2400th batch is: 9.195309\n",
            "the loss in 2600th batch is: 9.033653\n",
            "the loss in 2800th batch is: 8.952762\n",
            "the loss in 3000th batch is: 8.486856\n",
            "the loss in 3200th batch is: 8.619665\n",
            "the loss in 3400th batch is: 8.342361\n",
            "the loss in 3600th batch is: 8.092490\n",
            "the loss in 3800th batch is: 8.135656\n",
            "the loss in 4000th batch is: 7.978316\n",
            "#############################################################\n",
            "total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1244.000000\n",
            "purchase hr and ndcg @5 : 0.029851, 0.022505\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1580.000000\n",
            "purchase hr and ndcg @10 : 0.037914, 0.025106\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1808.000000\n",
            "purchase hr and ndcg @15 : 0.043385, 0.026545\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2003.000000\n",
            "purchase hr and ndcg @20 : 0.048065, 0.027649\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 7.714307\n"
          ]
        }
      ],
      "source": [
        "# Executing the python script \"SNQN_v2.py\" to train a SNQN model on the sampled data and evaluate it on validation data using HR (hit rate) and NDCG metrics for different values of k\n",
        "!ls /content/recommendation-system/ItemFeatures/HM/data/\n",
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py\" --model=GRU --data=\"/content/recommendation-system/ItemFeatures/HM/data/\" --epoch=9"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# SNQN (With and without Item Features) on RetailRocket Data\n",
        "\n",
        "In this notebook we train an SNQN model to recomend a ranked list of items to users in the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgK2r88Mmkd",
        "outputId": "f7ce3b63-ded9-4846-9776-71ac4a55375c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'recommendation-system'...\n",
            "remote: Enumerating objects: 1432, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 1432 (delta 118), reused 124 (delta 59), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1432/1432), 10.59 MiB | 16.18 MiB/s, done.\n",
            "Resolving deltas: 100% (748/748), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the git repository\n",
        "!rm -rf recommendation-system\n",
        "!git clone https://github.com/szheng3/recommendation-system.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3pkxR1AsDW",
        "outputId": "ace3f605-f8b6-4b3f-ede5-6e5d914e8470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# installing missing libraries\n",
        "!pip install trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the RetailRocket Dataset file from AWS S3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7SMHfSMiHI",
        "outputId": "f0d94ff5-58f1-49fb-fd1f-9b66e26ee928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-03 04:28:01--  https://szdataset.s3.us-east-2.amazonaws.com/531/rc_data.zip\n",
            "Resolving szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)... 52.219.110.146\n",
            "Connecting to szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)|52.219.110.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26020955 (25M) [application/zip]\n",
            "Saving to: ‘/content/rc_data.zip’\n",
            "\n",
            "rc_data.zip         100%[===================>]  24.82M  16.1MB/s    in 1.5s    \n",
            "\n",
            "2023-05-03 04:28:03 (16.1 MB/s) - ‘/content/rc_data.zip’ saved [26020955/26020955]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://szdataset.s3.us-east-2.amazonaws.com/531/rc_data.zip -P \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Unzip to get the data folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-MWI_XktTHX"
      },
      "outputs": [],
      "source": [
        "# Unzip to get the data folder\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"rc_data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# put item features csv in the same folder\n",
        "!cp -f \"/content/recommendation-system/ItemFeatures/Retailrocket/data/rc_item_features.csv\" \"/content/data\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SNQN model (when lambda=0)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUk2eLLkFX0g",
        "outputId": "159a78a7-0e76-4781-d573-c932b141d6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 04:28:05.444292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 04:28:07.166029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:159: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 04:28:10.535381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:10.993403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:10.993722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:330: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 04:28:17.288789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:17.289134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:17.289327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:19.480848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:19.481156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:19.481371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:19.481564: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 04:28:19.481612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 04:28:19.514844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 13.192978\n",
            "the loss in 400th batch is: 11.752443\n",
            "the loss in 600th batch is: 12.054474\n",
            "the loss in 800th batch is: 11.666016\n",
            "the loss in 1000th batch is: 12.106503\n",
            "the loss in 1200th batch is: 11.913157\n",
            "the loss in 1400th batch is: 11.706722\n",
            "the loss in 1600th batch is: 11.946686\n",
            "the loss in 1800th batch is: 11.632792\n",
            "the loss in 2000th batch is: 11.984845\n",
            "the loss in 2200th batch is: 11.297539\n",
            "the loss in 2400th batch is: 11.627330\n",
            "the loss in 2600th batch is: 11.490814\n",
            "the loss in 2800th batch is: 11.582947\n",
            "the loss in 3000th batch is: 11.676868\n",
            "the loss in 3200th batch is: 11.597917\n",
            "the loss in 3400th batch is: 11.203617\n",
            "the loss in 3600th batch is: 11.238206\n",
            "the loss in 3800th batch is: 11.296271\n",
            "the loss in 4000th batch is: 11.317117\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.200000\n",
            "clicks hr ndcg @ 5 : 0.000051, 0.000028\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 4.800000\n",
            "clicks hr ndcg @ 10 : 0.000203, 0.000076\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10.400000\n",
            "clicks hr ndcg @ 15 : 0.000355, 0.000117\n",
            "purchase hr and ndcg @15 : 0.000378, 0.000104\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 14.200000\n",
            "clicks hr ndcg @ 20 : 0.000473, 0.000145\n",
            "purchase hr and ndcg @20 : 0.000567, 0.000150\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 11.272763\n",
            "the loss in 4400th batch is: 11.187298\n",
            "the loss in 4600th batch is: 11.168108\n",
            "the loss in 4800th batch is: 11.249937\n",
            "the loss in 5000th batch is: 11.234127\n",
            "the loss in 5200th batch is: 11.171192\n",
            "the loss in 5400th batch is: 11.195910\n",
            "the loss in 5600th batch is: 11.187739\n",
            "the loss in 5800th batch is: 11.438143\n",
            "the loss in 6000th batch is: 11.127620\n",
            "the loss in 6200th batch is: 11.133413\n",
            "the loss in 6400th batch is: 11.150372\n",
            "the loss in 6600th batch is: 11.105958\n",
            "the loss in 6800th batch is: 11.230012\n",
            "the loss in 7000th batch is: 11.149794\n",
            "the loss in 7200th batch is: 11.226444\n",
            "the loss in 7400th batch is: 11.249125\n",
            "the loss in 7600th batch is: 11.137113\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/data/\" --epoch=2 --lambda_value=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRjKY1ukafMf"
      },
      "source": [
        "6. Run script to begin training and evaluate the SNQN model (when lambda=0.5)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFUkotpDazTh",
        "outputId": "f3249162-cff7-4ec2-ff26-54478c2d8669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 05:05:55.911172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 05:05:57.101341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:159: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 05:05:59.844222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:05:59.876220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:05:59.876535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:330: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 05:06:05.647389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:05.647743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:05.647933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:06.570213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:06.570510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:06.570712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:06:06.570857: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 05:06:06.570906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 05:06:06.604677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 11.650517\n",
            "the loss in 400th batch is: 11.377290\n",
            "the loss in 600th batch is: 11.015514\n",
            "the loss in 800th batch is: 11.052025\n",
            "the loss in 1000th batch is: 10.988722\n",
            "the loss in 1200th batch is: 11.080171\n",
            "the loss in 1400th batch is: 10.867297\n",
            "the loss in 1600th batch is: 10.613232\n",
            "the loss in 1800th batch is: 10.661792\n",
            "the loss in 2000th batch is: 10.463072\n",
            "the loss in 2200th batch is: 10.620358\n",
            "the loss in 2400th batch is: 10.477065\n",
            "the loss in 2600th batch is: 10.655181\n",
            "the loss in 2800th batch is: 10.274916\n",
            "the loss in 3000th batch is: 10.287071\n",
            "the loss in 3200th batch is: 10.351273\n",
            "the loss in 3400th batch is: 10.331765\n",
            "the loss in 3600th batch is: 10.192676\n",
            "the loss in 3800th batch is: 10.134361\n",
            "the loss in 4000th batch is: 10.228003\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 504.200000\n",
            "clicks hr ndcg @ 5 : 0.014420, 0.010357\n",
            "purchase hr and ndcg @5 : 0.030807, 0.024717\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 693.000000\n",
            "clicks hr ndcg @ 10 : 0.020075, 0.012185\n",
            "purchase hr and ndcg @10 : 0.041202, 0.028048\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 818.400000\n",
            "clicks hr ndcg @ 15 : 0.023853, 0.013182\n",
            "purchase hr and ndcg @15 : 0.048006, 0.029869\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 929.800000\n",
            "clicks hr ndcg @ 20 : 0.027251, 0.013986\n",
            "purchase hr and ndcg @20 : 0.053865, 0.031253\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 10.054839\n",
            "the loss in 4400th batch is: 9.901521\n",
            "the loss in 4600th batch is: 9.950852\n",
            "the loss in 4800th batch is: 10.664660\n",
            "the loss in 5000th batch is: 10.052534\n",
            "the loss in 5200th batch is: 10.147913\n",
            "the loss in 5400th batch is: 10.081882\n",
            "the loss in 5600th batch is: 10.572477\n",
            "the loss in 5800th batch is: 10.001560\n",
            "the loss in 6000th batch is: 10.212136\n",
            "the loss in 6200th batch is: 10.173399\n",
            "the loss in 6400th batch is: 9.952272\n",
            "the loss in 6600th batch is: 9.702217\n",
            "the loss in 6800th batch is: 9.858079\n",
            "the loss in 7000th batch is: 9.559168\n",
            "the loss in 7200th batch is: 10.035137\n",
            "the loss in 7400th batch is: 9.944024\n",
            "the loss in 7600th batch is: 9.492331\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/data/\" --epoch=2 --lambda_value=0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le01pCLWalDp"
      },
      "source": [
        "7. Run script to begin training and evaluate the SNQN model (when lambda=1.0)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "10396d01-0964-4f75-d42e-00bcc06a763b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 05:44:51.678877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 05:44:52.764851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:159: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 05:44:54.736952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:44:54.767070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:44:54.767339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py:330: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 05:45:00.423963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:00.424308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:00.424511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:01.327541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:01.327822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:01.328012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:45:01.328155: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 05:45:01.328205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 05:45:01.360140: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 10.911139\n",
            "the loss in 400th batch is: 10.663661\n",
            "the loss in 600th batch is: 10.475328\n",
            "the loss in 800th batch is: 10.407914\n",
            "the loss in 1000th batch is: 10.319840\n",
            "the loss in 1200th batch is: 10.184030\n",
            "the loss in 1400th batch is: 10.161119\n",
            "the loss in 1600th batch is: 9.815851\n",
            "the loss in 1800th batch is: 9.937162\n",
            "the loss in 2000th batch is: 9.360223\n",
            "the loss in 2200th batch is: 9.510178\n",
            "the loss in 2400th batch is: 9.124673\n",
            "the loss in 2600th batch is: 9.350524\n",
            "the loss in 2800th batch is: 9.477865\n",
            "the loss in 3000th batch is: 9.153607\n",
            "the loss in 3200th batch is: 8.809585\n",
            "the loss in 3400th batch is: 8.676858\n",
            "the loss in 3600th batch is: 9.117772\n",
            "the loss in 3800th batch is: 8.714710\n",
            "the loss in 4000th batch is: 8.722787\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5864.600000\n",
            "clicks hr ndcg @ 5 : 0.166374, 0.132384\n",
            "purchase hr and ndcg @5 : 0.364392, 0.315328\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6736.400000\n",
            "clicks hr ndcg @ 10 : 0.195611, 0.141855\n",
            "purchase hr and ndcg @10 : 0.398412, 0.326337\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7258.600000\n",
            "clicks hr ndcg @ 15 : 0.212694, 0.146368\n",
            "purchase hr and ndcg @15 : 0.420714, 0.332263\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7623.400000\n",
            "clicks hr ndcg @ 20 : 0.224773, 0.149222\n",
            "purchase hr and ndcg @20 : 0.435645, 0.335797\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.643984\n",
            "the loss in 4400th batch is: 8.468046\n",
            "the loss in 4600th batch is: 8.522318\n",
            "the loss in 4800th batch is: 8.522890\n",
            "the loss in 5000th batch is: 8.658485\n",
            "the loss in 5200th batch is: 8.585105\n",
            "the loss in 5400th batch is: 7.665242\n",
            "the loss in 5600th batch is: 8.249008\n",
            "the loss in 5800th batch is: 8.114547\n",
            "the loss in 6000th batch is: 7.960440\n",
            "the loss in 6200th batch is: 7.714670\n",
            "the loss in 6400th batch is: 7.594402\n",
            "the loss in 6600th batch is: 7.776797\n",
            "the loss in 6800th batch is: 7.441972\n",
            "the loss in 7000th batch is: 7.352092\n",
            "the loss in 7200th batch is: 7.421268\n",
            "the loss in 7400th batch is: 7.554626\n",
            "the loss in 7600th batch is: 7.591177\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/data/\" --epoch=2 --lambda_value=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Fa0ECScU3bX8"
      },
      "source": [
        "8. Run script to begin training and evaluate the SNQN model(without item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IPGdFA4j3bX8",
        "outputId": "55adfb2d-ee61-4531-ea43-6dee6676b4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 06:24:08.249608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 06:24:09.669505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_new.py:134: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 06:24:11.663731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:11.695961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:11.696253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_new.py:146: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,activation=None)\n",
            "/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_new.py:147: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,activation=None)\n",
            "2023-05-03 06:24:17.193156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:17.193531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:17.193739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:18.104468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:18.104747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:18.104941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 06:24:18.105089: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 06:24:18.105138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 06:24:18.134575: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.600000\n",
            "clicks hr ndcg @ 5 : 0.000025, 0.000011\n",
            "purchase hr and ndcg @5 : 0.000189, 0.000081\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 3.000000\n",
            "clicks hr ndcg @ 10 : 0.000085, 0.000030\n",
            "purchase hr and ndcg @10 : 0.000189, 0.000081\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4.400000\n",
            "clicks hr ndcg @ 15 : 0.000144, 0.000046\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000081\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 5.600000\n",
            "clicks hr ndcg @ 20 : 0.000194, 0.000058\n",
            "purchase hr and ndcg @20 : 0.000189, 0.000081\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.901163\n",
            "the loss in 400th batch is: 10.588593\n",
            "the loss in 600th batch is: 10.409131\n",
            "the loss in 800th batch is: 10.443048\n",
            "the loss in 1000th batch is: 10.236314\n",
            "the loss in 1200th batch is: 10.051517\n",
            "the loss in 1400th batch is: 10.121941\n",
            "the loss in 1600th batch is: 10.018421\n",
            "the loss in 1800th batch is: 9.796259\n",
            "the loss in 2000th batch is: 9.437099\n",
            "the loss in 2200th batch is: 9.488456\n",
            "the loss in 2400th batch is: 9.575273\n",
            "the loss in 2600th batch is: 9.290443\n",
            "the loss in 2800th batch is: 9.512407\n",
            "the loss in 3000th batch is: 8.748978\n",
            "the loss in 3200th batch is: 8.724233\n",
            "the loss in 3400th batch is: 8.834871\n",
            "the loss in 3600th batch is: 8.909552\n",
            "the loss in 3800th batch is: 8.911562\n",
            "the loss in 4000th batch is: 8.800484\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6001.000000\n",
            "clicks hr ndcg @ 5 : 0.171885, 0.135988\n",
            "purchase hr and ndcg @5 : 0.365526, 0.313483\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6901.400000\n",
            "clicks hr ndcg @ 10 : 0.202712, 0.145995\n",
            "purchase hr and ndcg @10 : 0.397845, 0.324066\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7439.800000\n",
            "clicks hr ndcg @ 15 : 0.220944, 0.150807\n",
            "purchase hr and ndcg @15 : 0.418068, 0.329440\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7807.800000\n",
            "clicks hr ndcg @ 20 : 0.233074, 0.153673\n",
            "purchase hr and ndcg @20 : 0.433377, 0.333071\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.324783\n",
            "the loss in 4400th batch is: 8.523460\n",
            "the loss in 4600th batch is: 8.285418\n",
            "the loss in 4800th batch is: 7.996543\n",
            "the loss in 5000th batch is: 8.084081\n",
            "the loss in 5200th batch is: 7.965319\n",
            "the loss in 5400th batch is: 7.619031\n",
            "the loss in 5600th batch is: 7.975140\n",
            "the loss in 5800th batch is: 7.943370\n",
            "the loss in 6000th batch is: 7.407940\n",
            "the loss in 6200th batch is: 7.547035\n",
            "the loss in 6400th batch is: 7.589402\n",
            "the loss in 6600th batch is: 7.553576\n",
            "the loss in 6800th batch is: 7.733659\n",
            "the loss in 7000th batch is: 7.787147\n",
            "the loss in 7200th batch is: 7.544521\n",
            "the loss in 7400th batch is: 7.460525\n",
            "the loss in 7600th batch is: 7.048398\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/Retailrocket/src/SNQN_new.py\" --model=GRU --data=\"/content/data/\" --epoch=2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
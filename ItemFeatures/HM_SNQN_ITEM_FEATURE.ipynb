{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# SNQN (With and without Item Features) on H&M Data\n",
        "\n",
        "In this notebook we train an SNQN model to recomend a ranked list of items to users in the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgK2r88Mmkd",
        "outputId": "c51aeda0-59ce-4ef9-9d8e-c1e196ae8fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'recommendation-system'...\n",
            "remote: Enumerating objects: 1432, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 1432 (delta 118), reused 124 (delta 59), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1432/1432), 10.59 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (748/748), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the git repository\n",
        "!rm -rf recommendation-system\n",
        "!git clone https://github.com/szheng3/recommendation-system.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3pkxR1AsDW",
        "outputId": "bee7ca65-0c6a-4117-d21e-b8fea54b8651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# installing missing libraries\n",
        "!pip install trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the RetailRocket Dataset file from AWS S3 bucket ( we get the data from the https://github.com/architkaila/recommenders_aipi590/blob/main/DRL_Recommenders/Dataset_2_HM/HM_SNQN_Recommender.ipynb notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7SMHfSMiHI",
        "outputId": "9cf56074-b6ce-4893-d3c2-4398ab68846b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-03 04:27:48--  https://szdataset.s3.us-east-2.amazonaws.com/531/hm_data.zip\n",
            "Resolving szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)... 52.219.84.8\n",
            "Connecting to szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)|52.219.84.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7098131 (6.8M) [application/zip]\n",
            "Saving to: ‘/content/hm_data.zip’\n",
            "\n",
            "hm_data.zip         100%[===================>]   6.77M  3.82MB/s    in 1.8s    \n",
            "\n",
            "2023-05-03 04:27:50 (3.82 MB/s) - ‘/content/hm_data.zip’ saved [7098131/7098131]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://szdataset.s3.us-east-2.amazonaws.com/531/hm_data.zip -P \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Unzip to get the data folder and put item features csv in the same folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-MWI_XktTHX"
      },
      "outputs": [],
      "source": [
        "# Unzip to get the data folder\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"hm_data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# put item features csv in the same folder\n",
        "!cp -f \"/content/recommendation-system/ItemFeatures/HM/data/hm_item_features.csv\" \"/content/hm_data\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SNQN model (when lambda=0)(with item features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUk2eLLkFX0g",
        "outputId": "9f4e1af3-9648-4db5-b2a7-90c0bc844e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 04:27:51.421548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 04:27:52.605483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:146: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 04:27:55.064994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:27:55.707049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:27:55.707409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:278: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:279: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:317: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 04:28:00.152276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:00.152692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:00.152914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:02.671311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:02.671635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:02.671829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:28:02.671969: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 04:28:02.672016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 04:28:02.706949: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 183874.625000\n",
            "the loss in 400th batch is: 114382.585938\n",
            "the loss in 600th batch is: 207110.296875\n",
            "the loss in 800th batch is: 120867.867188\n",
            "the loss in 1000th batch is: 61892.277344\n",
            "the loss in 1200th batch is: 132953.062500\n",
            "the loss in 1400th batch is: 232580.984375\n",
            "the loss in 1600th batch is: 87269.187500\n",
            "the loss in 1800th batch is: 270400.031250\n",
            "the loss in 2000th batch is: 128823.296875\n",
            "the loss in 2200th batch is: 64777.953125\n",
            "the loss in 2400th batch is: 70753.835938\n",
            "the loss in 2600th batch is: 96609.531250\n",
            "the loss in 2800th batch is: 43984.113281\n",
            "the loss in 3000th batch is: 72160.164062\n",
            "the loss in 3200th batch is: 25840.582031\n",
            "the loss in 3400th batch is: 28214.699219\n",
            "the loss in 3600th batch is: 89406.453125\n",
            "the loss in 3800th batch is: 59367.457031\n",
            "the loss in 4000th batch is: 37399.437500\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 318.000000\n",
            "purchase hr and ndcg @5 : 0.007631, 0.005190\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 493.000000\n",
            "purchase hr and ndcg @10 : 0.011830, 0.006541\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 645.000000\n",
            "purchase hr and ndcg @15 : 0.015478, 0.007508\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 791.000000\n",
            "purchase hr and ndcg @20 : 0.018981, 0.008332\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 42222.617188\n",
            "the loss in 4400th batch is: 24419.074219\n",
            "the loss in 4600th batch is: 33546.457031\n",
            "the loss in 4800th batch is: 25698.449219\n",
            "the loss in 5000th batch is: 24344.351562\n",
            "the loss in 5200th batch is: 19500.925781\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRjKY1ukafMf"
      },
      "source": [
        "6. Run script to begin training and evaluate the SNQN model (when lambda=0.5)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFUkotpDazTh",
        "outputId": "7facdd83-21d8-4c9e-96ee-d9f1dfe061ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 04:57:02.030331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 04:57:03.472978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:146: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 04:57:06.177947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:06.268900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:06.269219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:278: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:279: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:317: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 04:57:09.424524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:09.424995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:09.425284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:11.709412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:11.709726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:11.709929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 04:57:11.710105: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 04:57:11.710149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 04:57:11.743835: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 244090.890625\n",
            "the loss in 400th batch is: 147570.921875\n",
            "the loss in 600th batch is: 128805.406250\n",
            "the loss in 800th batch is: 197102.828125\n",
            "the loss in 1000th batch is: 122332.921875\n",
            "the loss in 1200th batch is: 89725.437500\n",
            "the loss in 1400th batch is: 74472.367188\n",
            "the loss in 1600th batch is: 43176.304688\n",
            "the loss in 1800th batch is: 59753.148438\n",
            "the loss in 2000th batch is: 105647.953125\n",
            "the loss in 2200th batch is: 34662.558594\n",
            "the loss in 2400th batch is: 98673.171875\n",
            "the loss in 2600th batch is: 43683.738281\n",
            "the loss in 2800th batch is: 51591.097656\n",
            "the loss in 3000th batch is: 67715.132812\n",
            "the loss in 3200th batch is: 31501.007812\n",
            "the loss in 3400th batch is: 37566.000000\n",
            "the loss in 3600th batch is: 14030.118164\n",
            "the loss in 3800th batch is: 36850.164062\n",
            "the loss in 4000th batch is: 61350.546875\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 304.000000\n",
            "purchase hr and ndcg @5 : 0.007295, 0.005127\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 469.000000\n",
            "purchase hr and ndcg @10 : 0.011254, 0.006396\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 627.000000\n",
            "purchase hr and ndcg @15 : 0.015046, 0.007393\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 772.000000\n",
            "purchase hr and ndcg @20 : 0.018525, 0.008213\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 15611.848633\n",
            "the loss in 4400th batch is: 74292.351562\n",
            "the loss in 4600th batch is: 31473.363281\n",
            "the loss in 4800th batch is: 23936.871094\n",
            "the loss in 5000th batch is: 22948.183594\n",
            "the loss in 5200th batch is: 22506.886719\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le01pCLWalDp"
      },
      "source": [
        "7. Run script to begin training and evaluate the SNQN model (when lambda=1.0)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "b1a16a8b-ece9-4e90-d9ef-56b9dd8a4037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 05:22:36.708306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 05:22:37.760826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:146: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 05:22:39.835180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:39.867881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:39.868159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:278: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:279: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:317: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 05:22:42.740351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:42.740728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:42.740923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:43.706330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:43.706672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:43.706890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:22:43.707041: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 05:22:43.707085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 05:22:43.739978: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 182865.859375\n",
            "the loss in 400th batch is: 162394.140625\n",
            "the loss in 600th batch is: 149353.531250\n",
            "the loss in 800th batch is: 18324.792969\n",
            "the loss in 1000th batch is: 148753.765625\n",
            "the loss in 1200th batch is: 43850.101562\n",
            "the loss in 1400th batch is: 64780.730469\n",
            "the loss in 1600th batch is: 112504.578125\n",
            "the loss in 1800th batch is: 19227.750000\n",
            "the loss in 2000th batch is: 13737.996094\n",
            "the loss in 2200th batch is: 18454.742188\n",
            "the loss in 2400th batch is: 57652.957031\n",
            "the loss in 2600th batch is: 36564.843750\n",
            "the loss in 2800th batch is: 14846.161133\n",
            "the loss in 3000th batch is: 9040.181641\n",
            "the loss in 3200th batch is: 30695.613281\n",
            "the loss in 3400th batch is: 18996.144531\n",
            "the loss in 3600th batch is: 126143.437500\n",
            "the loss in 3800th batch is: 6779.822266\n",
            "the loss in 4000th batch is: 6683.993164\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 319.000000\n",
            "purchase hr and ndcg @5 : 0.007655, 0.005174\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 470.000000\n",
            "purchase hr and ndcg @10 : 0.011278, 0.006336\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 602.000000\n",
            "purchase hr and ndcg @15 : 0.014446, 0.007172\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 721.000000\n",
            "purchase hr and ndcg @20 : 0.017301, 0.007847\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 42788.300781\n",
            "the loss in 4400th batch is: 6103.738281\n",
            "the loss in 4600th batch is: 18237.802734\n",
            "the loss in 4800th batch is: 17943.255859\n",
            "the loss in 5000th batch is: 7713.894043\n",
            "the loss in 5200th batch is: 11151.166016\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tnJno6s23VKO"
      },
      "source": [
        "8. Run script to begin training and evaluate the SNQN model(without item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI3DUhQK3VKO",
        "outputId": "8ef6a6b1-b14f-4a6c-ce7d-757b993025d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 05:47:59.630092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 05:48:00.762573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:141: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 05:48:02.803166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:02.837291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:02.837584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:152: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:153: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "2023-05-03 05:48:05.457528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:05.457913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:05.458188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:06.427381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:06.427683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:06.427890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 05:48:06.428037: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 05:48:06.428081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 05:48:06.457518: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 11.354027\n",
            "the loss in 400th batch is: 11.010880\n",
            "the loss in 600th batch is: 10.819208\n",
            "the loss in 800th batch is: 10.540666\n",
            "the loss in 1000th batch is: 10.551016\n",
            "the loss in 1200th batch is: 10.209102\n",
            "the loss in 1400th batch is: 9.996839\n",
            "the loss in 1600th batch is: 9.838075\n",
            "the loss in 1800th batch is: 9.849008\n",
            "the loss in 2000th batch is: 9.480510\n",
            "the loss in 2200th batch is: 9.610229\n",
            "the loss in 2400th batch is: 8.941610\n",
            "the loss in 2600th batch is: 9.053811\n",
            "the loss in 2800th batch is: 8.885318\n",
            "the loss in 3000th batch is: 8.488981\n",
            "the loss in 3200th batch is: 8.722538\n",
            "the loss in 3400th batch is: 8.545442\n",
            "the loss in 3600th batch is: 8.481924\n",
            "the loss in 3800th batch is: 7.959084\n",
            "the loss in 4000th batch is: 8.321503\n",
            "#############################################################\n",
            "total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1169.000000\n",
            "purchase hr and ndcg @5 : 0.028052, 0.021093\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1501.000000\n",
            "purchase hr and ndcg @10 : 0.036019, 0.023655\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1723.000000\n",
            "purchase hr and ndcg @15 : 0.041346, 0.025066\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1896.000000\n",
            "purchase hr and ndcg @20 : 0.045497, 0.026047\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 7.782660\n",
            "the loss in 4400th batch is: 7.355810\n",
            "the loss in 4600th batch is: 7.660406\n",
            "the loss in 4800th batch is: 7.350563\n",
            "the loss in 5000th batch is: 7.415452\n",
            "the loss in 5200th batch is: 7.089592\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
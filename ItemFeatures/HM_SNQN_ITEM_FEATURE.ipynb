{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ltyWBrP0cnH"
      },
      "source": [
        "# SNQN (With and without Item Features) on H&M Data\n",
        "\n",
        "In this notebook we train an SNQN model to recomend a ranked list of items to users in the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz3djcf0w7C"
      },
      "source": [
        "1. Clone the git repository containing all the source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgK2r88Mmkd",
        "outputId": "c51aeda0-59ce-4ef9-9d8e-c1e196ae8fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'recommendation-system'...\n",
            "remote: Enumerating objects: 1432, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 1432 (delta 118), reused 124 (delta 59), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1432/1432), 10.59 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (748/748), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the git repository\n",
        "!rm -rf recommendation-system\n",
        "!git clone https://github.com/szheng3/recommendation-system.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WLc6n_04S8"
      },
      "source": [
        "2. Install the missing libraries (specifically for google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3pkxR1AsDW",
        "outputId": "bee7ca65-0c6a-4117-d21e-b8fea54b8651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl) (1.22.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# installing missing libraries\n",
        "!pip install trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WblRLpti1A4h"
      },
      "source": [
        "3. Download the RetailRocket Dataset file from AWS S3 bucket ( we get the data from the https://github.com/architkaila/recommenders_aipi590/blob/main/DRL_Recommenders/Dataset_2_HM/HM_SNQN_Recommender.ipynb notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7SMHfSMiHI",
        "outputId": "9cf56074-b6ce-4893-d3c2-4398ab68846b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-03 04:27:48--  https://szdataset.s3.us-east-2.amazonaws.com/531/hm_data.zip\n",
            "Resolving szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)... 52.219.84.8\n",
            "Connecting to szdataset.s3.us-east-2.amazonaws.com (szdataset.s3.us-east-2.amazonaws.com)|52.219.84.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7098131 (6.8M) [application/zip]\n",
            "Saving to: ‘/content/hm_data.zip’\n",
            "\n",
            "hm_data.zip         100%[===================>]   6.77M  3.82MB/s    in 1.8s    \n",
            "\n",
            "2023-05-03 04:27:50 (3.82 MB/s) - ‘/content/hm_data.zip’ saved [7098131/7098131]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://szdataset.s3.us-east-2.amazonaws.com/531/hm_data.zip -P \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB5AbLV31Pjg"
      },
      "source": [
        "4. Unzip to get the data folder and put item features csv in the same folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-MWI_XktTHX"
      },
      "outputs": [],
      "source": [
        "# Unzip to get the data folder\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"hm_data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# put item features csv in the same folder\n",
        "!cp -f \"/content/recommendation-system/ItemFeatures/HM/data/hm_item_features.csv\" \"/content/hm_data\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNt1pnmh1aaI"
      },
      "source": [
        "5. Run script to begin training and evaluate the SNQN model (when lambda=0)(with item features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUk2eLLkFX0g",
        "outputId": "6963f666-45d2-4118-b3b6-d5af91b16643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 21:30:37.967433: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 21:30:39.151659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:151: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 21:30:41.704896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:42.185029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:42.185339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:283: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:284: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:323: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 21:30:44.915550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:44.915890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:44.916120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:48.674677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:48.674979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:48.675207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:30:48.675355: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 21:30:48.675403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 21:30:48.705325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 568442.062500\n",
            "the loss in 400th batch is: 466654.625000\n",
            "the loss in 600th batch is: 356827.875000\n",
            "the loss in 800th batch is: 496532.093750\n",
            "the loss in 1000th batch is: 236941.671875\n",
            "the loss in 1200th batch is: 319501.500000\n",
            "the loss in 1400th batch is: 315910.156250\n",
            "the loss in 1600th batch is: 407887.343750\n",
            "the loss in 1800th batch is: 189671.031250\n",
            "the loss in 2000th batch is: 177589.453125\n",
            "the loss in 2200th batch is: 249935.828125\n",
            "the loss in 2400th batch is: 175697.156250\n",
            "the loss in 2600th batch is: 98227.890625\n",
            "the loss in 2800th batch is: 167761.578125\n",
            "the loss in 3000th batch is: 189619.140625\n",
            "the loss in 3200th batch is: 101444.421875\n",
            "the loss in 3400th batch is: 141405.687500\n",
            "the loss in 3600th batch is: 518599.687500\n",
            "the loss in 3800th batch is: 54869.082031\n",
            "the loss in 4000th batch is: 74431.445312\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 23.000000\n",
            "purchase hr and ndcg @5 : 0.000552, 0.000365\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 44.000000\n",
            "purchase hr and ndcg @10 : 0.001056, 0.000533\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 48.000000\n",
            "purchase hr and ndcg @15 : 0.001152, 0.000559\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 50.000000\n",
            "purchase hr and ndcg @20 : 0.001200, 0.000570\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 171809.000000\n",
            "the loss in 4400th batch is: 159409.062500\n",
            "the loss in 4600th batch is: 221790.625000\n",
            "the loss in 4800th batch is: 400159.656250\n",
            "the loss in 5000th batch is: 117352.421875\n",
            "the loss in 5200th batch is: 88014.976562\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRjKY1ukafMf"
      },
      "source": [
        "6. Run script to begin training and evaluate the SNQN model (when lambda=0.5)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFUkotpDazTh",
        "outputId": "217917f2-029c-4f62-e1fd-79ec1c526c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 21:58:13.579234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 21:58:14.694792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:151: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 21:58:17.076909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:17.157668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:17.157979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:283: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:284: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:323: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 21:58:20.372258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:20.372620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:20.372811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:21.418999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:21.419362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:21.419567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 21:58:21.419716: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 21:58:21.419758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 21:58:21.452972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 241558.546875\n",
            "the loss in 400th batch is: 495947.062500\n",
            "the loss in 600th batch is: 344266.000000\n",
            "the loss in 800th batch is: 200035.578125\n",
            "the loss in 1000th batch is: 146364.765625\n",
            "the loss in 1200th batch is: 184365.781250\n",
            "the loss in 1400th batch is: 220153.343750\n",
            "the loss in 1600th batch is: 159893.703125\n",
            "the loss in 1800th batch is: 210973.921875\n",
            "the loss in 2000th batch is: 201992.078125\n",
            "the loss in 2200th batch is: 169675.937500\n",
            "the loss in 2400th batch is: 392570.750000\n",
            "the loss in 2600th batch is: 142804.250000\n",
            "the loss in 2800th batch is: 110383.007812\n",
            "the loss in 3000th batch is: 99044.546875\n",
            "the loss in 3200th batch is: 116688.617188\n",
            "the loss in 3400th batch is: 76417.843750\n",
            "the loss in 3600th batch is: 114534.414062\n",
            "the loss in 3800th batch is: 135620.484375\n",
            "the loss in 4000th batch is: 116480.468750\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 13.000000\n",
            "purchase hr and ndcg @5 : 0.000312, 0.000184\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20.000000\n",
            "purchase hr and ndcg @10 : 0.000480, 0.000240\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 21.000000\n",
            "purchase hr and ndcg @15 : 0.000504, 0.000246\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 22.000000\n",
            "purchase hr and ndcg @20 : 0.000528, 0.000252\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 79129.484375\n",
            "the loss in 4400th batch is: 127896.015625\n",
            "the loss in 4600th batch is: 254140.984375\n",
            "the loss in 4800th batch is: 179129.562500\n",
            "the loss in 5000th batch is: 89319.117188\n",
            "the loss in 5200th batch is: 66262.562500\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le01pCLWalDp"
      },
      "source": [
        "7. Run script to begin training and evaluate the SNQN model (when lambda=1.0)(with item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Zk3vmWxMdV",
        "outputId": "acfe5e2f-8fd9-49c6-e01f-ca919d1ee6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 22:22:38.992228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 22:22:39.978960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:151: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 22:22:42.484885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:42.516696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:42.517010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:283: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:284: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py:323: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embedding = tf.compat.v1.layers.dense(self.item_features, self.hidden_size + 1,\n",
            "2023-05-03 22:22:45.366438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:45.366787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:45.366988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:46.394384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:46.394683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:46.394884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:22:46.395032: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 22:22:46.395087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 22:22:46.428016: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 11.534196\n",
            "the loss in 400th batch is: 11.123375\n",
            "the loss in 600th batch is: 10.545776\n",
            "the loss in 800th batch is: 10.950585\n",
            "the loss in 1000th batch is: 10.310148\n",
            "the loss in 1200th batch is: 10.084901\n",
            "the loss in 1400th batch is: 10.030541\n",
            "the loss in 1600th batch is: 9.770090\n",
            "the loss in 1800th batch is: 9.859374\n",
            "the loss in 2000th batch is: 9.693110\n",
            "the loss in 2200th batch is: 9.485086\n",
            "the loss in 2400th batch is: 9.290375\n",
            "the loss in 2600th batch is: 9.210496\n",
            "the loss in 2800th batch is: 9.087620\n",
            "the loss in 3000th batch is: 8.663759\n",
            "the loss in 3200th batch is: 8.600520\n",
            "the loss in 3400th batch is: 8.250128\n",
            "the loss in 3600th batch is: 7.854578\n",
            "the loss in 3800th batch is: 7.989836\n",
            "the loss in 4000th batch is: 8.069075\n",
            "#############################################################\n",
            " total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1295.000000\n",
            "purchase hr and ndcg @5 : 0.031075, 0.023141\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1646.000000\n",
            "purchase hr and ndcg @10 : 0.039498, 0.025860\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1865.000000\n",
            "purchase hr and ndcg @15 : 0.044753, 0.027247\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2046.000000\n",
            "purchase hr and ndcg @20 : 0.049097, 0.028268\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 7.890499\n",
            "the loss in 4400th batch is: 7.680538\n",
            "the loss in 4600th batch is: 7.632821\n",
            "the loss in 4800th batch is: 7.372883\n",
            "the loss in 5000th batch is: 7.139511\n",
            "the loss in 5200th batch is: 7.119002\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_item_feature.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9 --lambda_value=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tnJno6s23VKO"
      },
      "source": [
        "8. Run script to begin training and evaluate the SNQN model(without item Features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI3DUhQK3VKO",
        "outputId": "e6773603-37ad-42c2-c816-8fea730d9bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-03 22:47:40.558237: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 22:47:41.549376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:141: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "2023-05-03 22:47:43.463545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:43.495330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:43.495592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:152: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py:153: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)\n",
            "2023-05-03 22:47:45.993815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:45.994165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:45.994367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:47.003808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:47.004133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:47.004353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-03 22:47:47.004504: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 22:47:47.004545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-03 22:47:47.034000: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "the loss in 200th batch is: 11.481880\n",
            "the loss in 400th batch is: 10.842067\n",
            "the loss in 600th batch is: 10.588864\n",
            "the loss in 800th batch is: 10.425772\n",
            "the loss in 1000th batch is: 10.169266\n",
            "the loss in 1200th batch is: 10.255031\n",
            "the loss in 1400th batch is: 10.170288\n",
            "the loss in 1600th batch is: 10.014536\n",
            "the loss in 1800th batch is: 9.567874\n",
            "the loss in 2000th batch is: 9.304061\n",
            "the loss in 2200th batch is: 9.416842\n",
            "the loss in 2400th batch is: 8.931561\n",
            "the loss in 2600th batch is: 8.868031\n",
            "the loss in 2800th batch is: 8.787237\n",
            "the loss in 3000th batch is: 8.701180\n",
            "the loss in 3200th batch is: 8.786078\n",
            "the loss in 3400th batch is: 8.392155\n",
            "the loss in 3600th batch is: 7.956622\n",
            "the loss in 3800th batch is: 8.336691\n",
            "the loss in 4000th batch is: 7.788951\n",
            "#############################################################\n",
            "total purchase:41673\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1181.000000\n",
            "purchase hr and ndcg @5 : 0.028340, 0.021394\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1551.000000\n",
            "purchase hr and ndcg @10 : 0.037218, 0.024258\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 1787.000000\n",
            "purchase hr and ndcg @15 : 0.042881, 0.025746\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 1971.000000\n",
            "purchase hr and ndcg @20 : 0.047297, 0.026787\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 7.536831\n",
            "the loss in 4400th batch is: 7.377294\n",
            "the loss in 4600th batch is: 7.652298\n",
            "the loss in 4800th batch is: 7.605828\n",
            "the loss in 5000th batch is: 7.110456\n",
            "the loss in 5200th batch is: 6.817802\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/recommendation-system/ItemFeatures/HM/src/SNQN_new.py\" --model=GRU --data=\"/content/hm_data/\" --epoch=9\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}